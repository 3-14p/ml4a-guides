{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks: Character RNNs with Keras\n",
    "\n",
    "Often we are not interested in isolated datapoints, but rather datapoints within a context of others. A datapoint may mean something different depending on what's come before it. This can typically be represented as some kind of _sequence_ of datapoints, perhaps the most common of which is a time series.\n",
    "\n",
    "One of the most ubiquitous sequences of data where context is especially important is natural language. We have quite a few words in English where the meaning of a word may be totally different depending on it's context. An innocuous example of this is \"bank\": \"I went fishing down by the river bank\" vs \"I deposited some money into the bank\".\n",
    "\n",
    "If we consider that each word is a datapoint, most non-recurrent methods will treat \"bank\" in the first sentence exactly the same as \"bank\" in the second sentence - they are indistinguishable. If you think about it, in isolation they are indistinguishable to us as well - it's the same word!\n",
    "\n",
    "We can only start to discern them when we consider the previous word (or words). So we might want our neural network to consider that \"bank\" in the first sentence is preceded by \"river\" and that in the second sentence \"money\" comes a few words before it. That's basically what RNNs do - they \"remember\" some of the previous context and that influences the output it produces. This \"memory\" (called the network's \"_hidden state_\") works by retaining some of the previous outputs and combining it with the current input; this recursing (feedback) of the network's output back into itself is where its name comes from.\n",
    "\n",
    "This recursing makes RNNs quite deep, and thus they can be difficult to train. The gradient gets smaller and smaller the deeper it is pushed backwards through the network until it \"vanishes\" (effectively becomes zero), so long-term dependencies are hard to learn. The typical practice is to only extend the RNN back a certain number of time steps so the network is still trainable.\n",
    "\n",
    "Certain units, such as the LSTM (long short-term memory) and GRU (gated recurrent unit), have been developed to mitigate some of this vanishing gradient effect.\n",
    "\n",
    "Let's walkthrough an example of a character RNN, which is a great approach for learning a character-level language model. A language model is essentially some function which returns a probability over possible words (or in this case, characters), based on what has been seen so far. This function can vary from region to region (e.g. if terms like \"pop\" are used more commonly than \"soda\") or from person to person. You could say that a (good) language model captures the style in which someone writes.\n",
    "\n",
    "Language models often must make the simplifying assumption that only what came immediately (one time step) before matters (this is called the \"Markov assumption\"), but with RNNs we do not need to make such an assumption.\n",
    "\n",
    "We'll use Keras which makes building neural networks extremely easy (this example is an annotated version of Keras's [LSTM text generation example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py)).\n",
    "\n",
    "First we'll do some simple preparation - import the classes we need and load up the text we want to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "# load up our text\n",
    "text = open('../assets/input_text.txt', 'r').read()\n",
    "\n",
    "# extract all (unique) characters\n",
    "# these are our \"categories\" or \"labels\"\n",
    "chars = list(set(text))\n",
    "\n",
    "# set a fixed vector size\n",
    "# so we look at specific windows of characters\n",
    "max_len = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define our RNN. Keras makes this trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(max_len, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're framing our task as a classification task. Given a sequence of characters, we want to predict the next character. We equate each character with some label or category (e.g. \"a\" is 0, \"b\" is 1, etc).\n",
    "\n",
    "We use the _softmax_ activation function on our output layer - this function is used for categorical output. It turns the output into a probability distribution over the categories (i.e. it makes the values the network outputs sum to 1). So the network will essentially tell us how strongly it feels about each character being the next one.\n",
    "\n",
    "The categorical cross-entropy loss the standard loss function for multilabel classification, which basically penalizes the network more the further off it is from the correct label.\n",
    "\n",
    "We use dropout here to prevent overfitting - we don't want the network to just return things already in the text, we want it to have some wiggle room and create novelty! Dropout is a technique where, in training, some percent (here, 20%) of random neurons of the associated layer are \"turned off\" for that epoch. This prevents overfitting but preventing the network from relying on particular neurons.\n",
    "\n",
    "That's it for the network architecture!\n",
    "\n",
    "To train, we have to do some additional preparation. We need to chop up the text into character sequences of the length we specified (`max_len`) - these are our training inputs. We match them with the character that immediately follows each sequence. These are our expected training outputs.\n",
    "\n",
    "For example, say we have the following text (this quote is from Zhuang Zi). With `max_len=20`, we could manually create the first couple training examples like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"The fish trap exists because of the fish. Once you have gotten the fish you can forget the trap. The rabbit snare exists because of the rabbit. Once you have gotten the rabbit, you can forget the snare. Words exist because of meaning. Once you have gotten the meaning, you can forget the words. Where can I find a man who has forgotten words so that I may have a word with him?\"\n",
    "\n",
    "# step size here is 3, but we can vary that\n",
    "input_1 = text[0:20]\n",
    "true_output_1 = text[20]\n",
    "# >>> 'The fish trap exists'\n",
    "# >>> ' '\n",
    "\n",
    "input_2 = text[3:23]\n",
    "true_output_2 = text[23]\n",
    "# >>> 'fish trap exists be'\n",
    "# >>> 'c'\n",
    "\n",
    "input_3 = text[6:26]\n",
    "true_output_3 = text[26]\n",
    "# >>> 'sh trap exists becau'\n",
    "# >>> 's'\n",
    "\n",
    "# etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generalize this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step = 3\n",
    "inputs = []\n",
    "outputs = []\n",
    "for i in range(0, len(text) - max_len, step):\n",
    "    inputs.append(text[i:i+max_len])\n",
    "    outputs.append(text[i+max_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to map each character to a label and create a reverse mapping to use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_labels = {ch:i for i, ch in enumerate(chars)}\n",
    "labels_char = {i:ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start constructing our numerical input 3-tensor and output matrix. Each input example (i.e. a sequence of characters) is turned into a matrix of one-hot vectors; that is, a bunch of vectors where the index corresponding to the character is set to 1 and all the rest are set to zero.\n",
    "\n",
    "For example, if we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assuming max_len = 7\n",
    "# so our examples have 7 characters\n",
    "example = 'cab dab'\n",
    "char_labels = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    ' ' : 4\n",
    "}\n",
    "\n",
    "# matrix form\n",
    "# the example uses only five kinds of characters,\n",
    "# so the vectors only need to have five components,\n",
    "# and since the input phrase has seven characters,\n",
    "# the matrix has seven vectors.\n",
    "[\n",
    "    [0, 0, 1, 0, 0], # c\n",
    "    [1, 0, 0, 0, 0], # a\n",
    "    [0, 1, 0, 0, 0], # b\n",
    "    [0, 0, 0, 0, 1], # (space)\n",
    "    [0, 0, 0, 1, 0], # d\n",
    "    [1, 0, 0, 0, 0], # a\n",
    "    [0, 1, 0, 0, 0]  # b\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That matrix represents a _single_ training example, so for our full set of training examples, we'd have a stack of those matrices (hence a 3-tensor).\n",
    "\n",
    "![A 3-tensor of training examples](../assets/rnn_3tensor.png)\n",
    "\n",
    "And the outputs for each example are each a one-hot vector (i.e. a single character). With that in mind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\x93': 0, '\\x97': 1, ' ': 2, '(': 3, ',': 4, '0': 5, '4': 6, '8': 7, '\\xc3': 8, 'D': 9, 'H': 10, 'L': 11, 'P': 12, 'T': 13, 'X': 14, 'd': 15, 'h': 16, 'l': 17, 'p': 18, 't': 19, 'x': 20, '|': 21, '\\x80': 22, '\\x94': 23, '\\x9c': 24, '+': 25, '\\xb0': 26, '3': 27, '7': 28, ';': 29, '?': 30, 'C': 31, 'G': 32, 'K': 33, 'O': 34, 'S': 35, 'W': 36, '[': 37, '_': 38, 'c': 39, 'g': 40, 'k': 41, 'o': 42, 's': 43, 'w': 44, '\\x85': 45, '\\n': 46, '\\x99': 47, '\\x9d': 48, '.': 49, '2': 50, '6': 51, ':': 52, '\\xbd': 53, 'B': 54, 'F': 55, 'J': 56, 'N': 57, 'R': 58, 'V': 59, 'Z': 60, 'b': 61, 'f': 62, 'j': 63, 'n': 64, 'r': 65, 'v': 66, 'z': 67, '\\xa6': 68, ')': 69, '-': 70, '1': 71, '5': 72, '\\xb6': 73, '9': 74, 'A': 75, '\\xc2': 76, 'E': 77, 'I': 78, 'M': 79, 'U': 80, 'Y': 81, ']': 82, 'a': 83, '\\xe2': 84, 'e': 85, 'i': 86, 'm': 87, 'q': 88, 'u': 89, 'y': 90}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using bool to reduce memory usage\n",
    "X = np.zeros((len(inputs), max_len, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(inputs), len(chars)), dtype=np.bool)\n",
    "\n",
    "# set the appropriate indices to 1 in each one-hot vector\n",
    "for i, example in enumerate(inputs):\n",
    "    for t, char in enumerate(example):\n",
    "        X[i, t, char_labels[char]] = 1\n",
    "    y[i, char_labels[outputs[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training data, we can start training. Keras also makes this easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# more epochs is usually better, but training can be very slow if not on a GPU\n",
    "epochs = 10\n",
    "model.fit(X, y, batch_size=128, nb_epoch=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's much more fun to see your network's ramblings as it's training, so let's write a function to produce text from the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(temperature=0.35, seed=None, predicate=lambda x: len(x) < 100):\n",
    "    if seed is not None and len(seed) < max_len:\n",
    "        raise Exception('Seed text must be at least {} chars long'.format(max_len))\n",
    "\n",
    "    # if no seed text is specified, randomly select a chunk of text\n",
    "    else:\n",
    "        start_idx = random.randint(0, len(text) - max_len - 1)\n",
    "        seed = text[start_idx:start_idx + max_len]\n",
    "\n",
    "    sentence = seed\n",
    "    generated = sentence\n",
    "\n",
    "    while predicate(generated):\n",
    "        # generate the input tensor\n",
    "        # from the last max_len characters generated so far\n",
    "        x = np.zeros((1, max_len, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_labels[char]] = 1.\n",
    "\n",
    "        # this produces a probability distribution over characters\n",
    "        probs = model.predict(x, verbose=0)[0]\n",
    "\n",
    "        # sample the character to use based on the predicted probabilities\n",
    "        next_idx = sample(probs, temperature)\n",
    "        next_char = labels_char[next_idx]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated\n",
    "\n",
    "def sample(probs, temperature):\n",
    "    \"\"\"samples an index from a vector of probabilities\"\"\"\n",
    "    a = np.log(probs)/temperature\n",
    "    a = np.exp(a)/np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _temperature_ controls how random we want the network to be. Lower temperatures favors more likely values, whereas higher temperatures introduce more and more randomness. At a high enough temperature, values will be chosen at random.\n",
    "\n",
    "With this generation function we can modify how we train the network so that we see some output at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('epoch', 0)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 4.9920\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ish. Once you have giIiattTaeiretwueh�3aKnVntJaeehaec�tsaheuIcrnhatnea:gtahrNi�ywfhxctncaaataimoIaPh\n",
      "('epoch', 1)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 3.7086\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ish. Once you have gi  wey gya;ff e  ieCyeg] ttsvsof cgccl as a ictcunis csn ases�vuVnes sf? c  zefe\n",
      "('epoch', 2)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 3.0007\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e. Words exist becaurnhn.g im naye. fatn af ho riiur  na ur  f aitbgneuray  gtangmofra aaii iaig.f.f\n",
      "('epoch', 3)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.9702\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ou can forget the trasmwoseireui�m uf ecinntee  uhgeWeuee icfeu[kae Wryhaureeeaeoiei iit tis  coruu.\n",
      "('epoch', 4)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.9315\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "fish. Once you have . frghI a  b to    frgc fr tsfn.  s a tg affdgm cg h f  d  ua c    d cra au  .  \n",
      "('epoch', 5)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.9223\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "s exist because of m. ceafthafnuitueanaaniuammnu  vthetsnra geaa .tave) ee.ntseeienaaafeeaearyn�e.rh\n",
      "('epoch', 6)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.9171\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "the fish you can for nb   I  r  Ce a it a e3 s ae� cta nsns  eerd uoa�t Wgnr  ra   s  ab hbet6h gtem\n",
      "('epoch', 7)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.8477\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "has forgotten words fm ggutsi vi hmrav.aanaaog  .ymaho,I ae hntwg  mrynrthe.  eusfitahtyceursttcgi .\n",
      "('epoch', 8)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.8775\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "forget the words. WheI fa.� eemins hs f vus  tt      ie aeY aatt ye   aic tneI   e aveu g m uWaeefe \n",
      "('epoch', 9)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.7918\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " words. Where can I  ei cgtyesinaety hvgaCdrhafaotg eienwfn�eegaa ahiviit.d itogshe   v.ticfegeoheIo\n",
      "('epoch', 10)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.8527\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "the fish you can for  hf r o   ta .s-cg  egan a mo e.tI et yiieteraf    at te oea rne   a.u y f  .tf\n",
      "('epoch', 11)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.8677\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " gotten the meaning,Eahyreoefhn. hnahemfafg ohhhevtuu  arahimbamnr .bh 1.anhytuaa  euaegIsfa airnWLa\n",
      "('epoch', 12)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.8818\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "it. Once you have goi  iy bigu theev teeyra abnme aesiftnoetagm .fnw  eghg  iseg evb e e ainafae ts \n",
      "('epoch', 13)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.8636\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " fish you can forgetieca �ooai inMytsrttmsf qhKrc  geufafgweha tioabgaaac erMvrec  ragi st hasaa.ene\n",
      "('epoch', 14)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.8248\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " gotten the fish youge y .er mt ee ceeuh�w   aehr uu e n t.fehheun miht   e  v .en. r..  .m tws  e e\n",
      "('epoch', 15)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.6991\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "Once you have gotteniiaaa)ouetng cgvraamaurGumiaed rm�Jt oha qasc  asihe�ssiooit eagfgfsi Ieu  o-Cea\n",
      "('epoch', 16)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.8912\n",
      "('\\n\\ttemperature:', 1.0)\n",
      ". Once you have gott  t v  gtifgege D I a.tre  e c ntug n  tg tgv  fignnetggc   agtdegeef vg nrteg  \n",
      "('epoch', 17)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.8913\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "the meaning, you cangge.heiu   .eeuribmubtnw ie  onu c afr bnu.gaag tnon  gu r oe na ga yebeveIhyoef\n",
      "('epoch', 18)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.7962\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " have gotten the fisr ryr aii.eryac wntfborirthvrir rnyrLefaoeui atta veftrg WineIer ebhe Wse.gy   r\n",
      "('epoch', 19)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.8270\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "en the fish you can b fhvyyc   ygi uee g uhc uyaasabae n veae  en ecW Ieahs v vaazueYe   a if h an h\n",
      "('epoch', 20)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.8743\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "fish. Once you have rtraa  r   nhtifiensychtetenne gtesveito iafigsbugaahIggniy atg s thahuatca ihg \n",
      "('epoch', 21)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.6528\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "at I may have a wordhft o rb h aah Uhsf.rrr . w eeaattue ac vtae ar.teaeIbu hnnwn nan eie I5h nm e e\n",
      "('epoch', 22)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.5555\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "n the rabbit, you caeiaafvevggtrne\n",
      "err. WbhuIhvbusafeuxang s  otcaaihieeori o  yiv et.teo rheueuiehi\n",
      "('epoch', 23)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.4456\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ten the meaning, youy)aa Wia c mbn .a ac   ahe au    an  h.rWhhhnaayyhonbc    tae   nheend2 reahmnba\n",
      "('epoch', 24)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.5226\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "fish. Once you have  tg d t Hotetts  a isgossoha aeufae Istaott ttgg tt igya  a  uc.a  fn oe  ttittt\n",
      "('epoch', 25)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.9199\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " forget the trap. Theucsyfbuonass   iesehU ivn fuyahganaeg iweiae efniaethoesiwea neae Isaaofosauga \n",
      "('epoch', 26)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.4975\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "are exists because o   nee egier?nai  uugh  be u vvgwa.  vi te v  ni Bt tn;i  rieemvrtcaoia  �  vgne\n",
      "('epoch', 27)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.4693\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "n I find a man who h7I ua b ai airncnfh ou  gabt gbrtcn iaa nahaf  yB.uahehC m ec. hauiaernosfnhia.e\n",
      "('epoch', 28)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.4975\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "you have gotten the     y cbi ogitatiI -.  ubehats .�tutiIrc ei i.r t  i   e efiae .   gttog g  t t \n",
      "('epoch', 29)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.7659\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "n the meaning, you cgyhgn aatv tvt harb  h o�oiggib gnt.  Faohuctaatafyvuift.ttt  iiifv nauyfvcidNu.\n",
      "('epoch', 30)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.4042\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "fish you can forget  erehgt h rhcryImafoaeae rar. re.o4yhuuaraeov ee e -  or uo n  mi anhb rmhuinda \n",
      "('epoch', 31)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.1675\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "get the snare. Wordsg ywnisadg itihiegoavh�fvgagafvrotinn.ht .lonrfayv�vfgvrgtwt  ygwawtEgFcwwaeWaoh\n",
      "('epoch', 32)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.1088\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "gotten words so thataIyeeheibeeeu yeieJeIesI sess seaeIsseee  issescee e seegevseeees eee s   sa m e\n",
      "('epoch', 33)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.3135\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "because of meaning.  et ryho.awatagtaisnaiawft n hhiy ga  it tm� aiett hmwhhhYyaWiwmi aa,gttwtgg tvt\n",
      "('epoch', 34)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.6353\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ords. Where can I fiCoe.et    �uuyuu�u    e   mneamn..eWnaotafa v o v ggie .tungotaoi aeigg r  myWWy\n",
      "('epoch', 35)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.4525\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "nce you have gotten iings Ig btu  cyuaaagcftI tmtgiieiee  erf n\n",
      "ayccuyuaybyaaaatf iaieieiieefIhg  d \n",
      "('epoch', 36)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.6917\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ave gotten the meanie9auoafgmafa f  te   W.oohansnmaaaWtmenhrrtamn  .arrhtfionatvaeot geata\n",
      "a] eoame\n",
      "('epoch', 37)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.3999\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "gotten the fish you aWwf n  v  ge.    rwnatWgrmaaieian  bah n  afgtghvgtgte  na o ryuaogfbhavenchna \n",
      "('epoch', 38)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.1455\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ecause of meaning. OncnyWgoheafftog teearh.irurRWuha  ffe  y gnKehii.3eruowy vaigub ge rIi hhhdihih_\n",
      "('epoch', 39)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s - loss: 2.0437\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "you can forget the wn ie .n ruyysbUff tttemie  ie  cc ou0neIsvogv he  e r.  oeebe r e gi fget eu ss \n",
      "('epoch', 40)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.1091\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ish trap exists becasc aie iy gidr nir.yeytstaaty2agfgaaenici fa i.ey rean  gto.fag  gieh aro uaavat\n",
      "('epoch', 41)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.8845\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "meaning, you can forngggete n...ehihWWecu y  feggggg et eee . ahhWauhar f e a ie t  i r nyy+ eeeg bs\n",
      "('epoch', 42)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.7736\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e you have gotten th  ah nigaIca b cn h.nt nt rwnmnt haotttnwa.Laaanww rrXhag gtetimrrwbhaaaimnywaan\n",
      "('epoch', 43)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.8206\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "et the snare. Words u bssdc aIefefcas scsas c  hayc sccce ecsseh  eeeri  n  scssc o d ff ag   siccc \n",
      "('epoch', 44)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.8343\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e of the fish. Once ya gggtt n et . o.nhuy�ww Igwotttrtt nnrrhw,hdaIddfefwyaafivt|ogNnfggtarWne g  n\n",
      "('epoch', 45)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.7804\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e fish you can forge  � e nr. .rsyhhIanaha aoaagieee n  ar. erh  s   oneauoaaeafiaerc ea c i  hct tc\n",
      "('epoch', 46)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.6348\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "have gotten the rabbeeihyhdy yo .s IIeshsegrmieiIheiifys obufv ogggsggvt  ieianateau  v ttfo gg tiu \n",
      "('epoch', 47)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.6020\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " Once you have gottener.marnrirmmWWdhyuhdahwhhwywwaaw hiir0  r(nrtoN4rr��en.hhhhhghrhdaeaaa   nn ri \n",
      "('epoch', 48)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.1309\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "rget the words. Wherb faIoiihhagi  istgfvc gfgggv.gft tgc   o o ffgvg  co oneooeoayfvfn ni  aa asyss\n",
      "('epoch', 49)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.8699\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "se of the rabbit. Onsahd aebaI e aes T eIoeraaeahiIeen aiIaanaa caarhaoiiettnti trmi  asc a ca ao wa\n",
      "('epoch', 50)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.1747\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "fish. Once you have  ts   tenieemnt ne.     aveuoo af ottt t       .  c   yyootnttt   t   e he  yy u\n",
      "('epoch', 51)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 2.0237\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "en the fish you can  fgrgec.ennnnmheWhaonawaauaonwaan neecir   ..hahaecuaaofhaghgttee rnc rr  vgbaga\n",
      "('epoch', 52)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.7377\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "re can I find a man r e wwftffg ht ttrthuc5nr5  cyraryuuyw rn.hhg  irrrinrm r�wgtt ehVuhuofwwWhwrmia\n",
      "('epoch', 53)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.5747\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ning. Once you have   ttt  owemiamtn t ouahnfuoaaafuoawata.   cr   �1yWihth no e�Waghtne.i.trrIoof  \n",
      "('epoch', 54)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.4653\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ou can forget the trrnn...thayoa yyrydafa ggte  eieihemx  yyruuy  nfvfecttgnihge  reWuy a ayyfantmne\n",
      "('epoch', 55)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.4704\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e gotten the fish yo hasg sEnat cc chhmi         n nnohtatf hh httttgawuc s cc i y 2ofe.erao.  o. to\n",
      "('epoch', 56)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.3995\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e words. Where can IIIIfs  ine iIeeeuoWuhyWyeaonf aefeeemIeeeee .ehyyy uda uaffae et etneeen . c n a\n",
      "('epoch', 57)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.3352\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "an forget the snare. Wy db sua  bsufsasmiiTit  ecI  c  f vu    vohhhehhoghgggahgt  i r   r y      aa\n",
      "('epoch', 58)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1849\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "the fish you can forv af eine .ooooouhaggaoattt iterrryi  .hh ayadyatraaagtt t  rIiiieirrrr nuantaaa\n",
      "('epoch', 59)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1914\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "re. Words exist becaseeee  aeae  saaab eseba ms  s eaa ee aeb eIeu a siss baaese.uescs essss aaseese\n",
      "('epoch', 60)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.4984\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e you have gotten thaera ov aur r anmrI rihIhhihrhhhaahwhrr�rg xvvv T v rrrrwaagitnniiihihhhaaar  fg\n",
      "('epoch', 61)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.4185\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "rds exist because ofseei  ea. h n csub  aeetg  t nhoch aiiat  aaohtah rnn     ithiiaa  ngaaaowggtntm\n",
      "('epoch', 62)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.2669\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "are exists because oeeee e bb ee n  uub efofeegoeo  e enincuyuyu  uunuoogtt  i eeen nn n nhyy ow fuo\n",
      "('epoch', 63)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.2063\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " you have gotten theh aniihmaaIag  a  gnrt  rrhwrrh.aw.wwwwawahhidiharrrrrrrrirrrimr|lbrdwarUeaaSxaw\n",
      "('epoch', 64)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1075\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "f the rabbit. Once y r�efv g  tttnnuhotifyffatuuuyy cW   cc     seeane  nn o .oaobbfs uaoofaftit  bs\n",
      "('epoch', 65)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.9127\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "of the fish. Once yo  ggvo itgt t ueahewahhagho faaniig  g r    ocytg    thththhhnh.rrhwhhwVvgav    \n",
      "('epoch', 66)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1130\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "get the trap. The rayureb daaI t iIashIIaafagggrana?|cqc rhr    aoti h .oeoowahnaanara tt e hethr  h\n",
      "('epoch', 67)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1198\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "s so that I may have   hrrrrwhhtwiiitiiahhhrhriy�            rrttg )hihho?WhwrhrIaa gtrr  rrwiKrirrw\n",
      "('epoch', 68)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1965\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "sh trap exists becausga agfmee eeeiecnnn u u afge eee e hoohenueyefeegeeeeah Ib.   ee fee e eg  gee \n",
      "('epoch', 69)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.0998\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "you have gotten the iain ng hda ynaa nahtoaahgti iriio rh        afoZfgowhhgthhnhte|W yyc rr       a\n",
      "('epoch', 70)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.9610\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "et the words. Where bIaaIIhiffaeiIdsfai vr yac  sfs vlsuv tgther hb ssa    aabdfasfIi egie h i.sl gl\n",
      "('epoch', 71)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.6863\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "of the rabbit. Once y asuggvggtttt tuheinc  naonu a afn   uWooguuhuhhort fhnmhamaan     y aff cah tt\n",
      "('epoch', 72)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.6406\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ts because of the fis.ie ncccyWa  vgovgg t  t rnaenninghIghhuyouynWncfh  r rr eiencn . ..cmwnIaffoet\n",
      "('epoch', 73)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.6949\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "gotten the meaning, yoa  aa  onf tttt  hhwime+oa.yyyaaaatt   hfW iiuiirnc  aahht   et  cg�ofhtr    g\n",
      "('epoch', 74)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.6535\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "en words so that I mawhhifee  arrrrhwntt    c aahradIaa narwn nnnrrgSiggwrrootinoWhWhar...owarrry  a\n",
      "('epoch', 75)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.7465\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "s because of the fissccc css  fggg e   c .hh ccuaff ttgn      rnrhy   fooofgehhhhgg irhhhy y  g   vc\n",
      "('epoch', 76)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1900\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " have gotten the fisn gguuhduafatfgufu utnnii  i  c c o uoaafnftggttttn  orrn.ey.WuuWuIauawwwraoo   \n",
      "('epoch', 77)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.5596\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "forget the trap. Theydebs f  eag   eii  eeec h a.ec ee.e n  enhhi .ei u eiiuna  e  iiiieienen   uu e\n",
      "('epoch', 78)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.4735\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "have gotten the meangnguhyy f nnfnnung gcnirer�uuocWc neWheyWfgiimnnrh rhigeei  c c uuyvvvvvgg te n \n",
      "('epoch', 79)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.9348\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "gotten the fish you aeg ann.ie ei immnnn  otttt eno caaaauhhaabI anh hrrr ii i rrriwirhidagog Wyhfia\n",
      "('epoch', 80)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.8070\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e snare. Words exist b bseseifffeeee aaeeessssuyc uu  saseee essee run ns sn  oa  s  aaoogWc.h hhux.\n",
      "('epoch', 81)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5813\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "u have gotten the metnigguhyu aWannnoayf nt  m mmorauaaohXhaawawhwwaarr r  rr rrrr rrrrranhhhhhaahaa\n",
      "('epoch', 82)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.4277\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "have gotten the rabbimgchyubauaa  fj i   t  ii    Woaffawfwggwn to�uerr  c etoe.mwaaIhawahhahhebc   \n",
      "('epoch', 83)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.3207\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " exists because of tee ese i    c yhyaeeeeeeegh hhhini  s ee  fg     gt oehu ogohafwhhhahhaai  rr   \n",
      "('epoch', 84)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.3095\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "at I may have a wordawhhhhiiie gihrhimgi   ig   tff     aa oho  aoKaf fhhhnr rrr r   r cc  .rrwhhihi\n",
      "('epoch', 85)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.3043\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " you have gotten themiainigg uyu ufan  oat tntnoemmho Woagh  uarWnahwhhrhmmy irniirrr irrrrttwwhhuqW\n",
      "('epoch', 86)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.3175\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ds so that I may havenh arrrwwhhhhiii igarrhritr   g    .R.rraavaaahhmhhhhh  o vr          r rhhhghg\n",
      "('epoch', 87)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.3644\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "so that I may have a rwrrwwhhhhiiiiighhhiiitii vvgt  f vg ggo fatmhgnaahhnh a.huyy rrt         ii im\n",
      "('epoch', 88)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.4684\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " the fish you can fo  vs  eenhnrre.Waawhgeeba bbafaaa.    issses   s      g�caaaa..hhohhhtt t       \n",
      "('epoch', 89)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5160\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "the fish you can forg t   e  nre..W.hhhwawwwwhaaffgggg    rirrrer ccyWhoowhwhdafofgnh r iirIrrrr   y\n",
      "('epoch', 90)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.6151\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " I find a man who haggffggtttt) trr r c yy yWuaabawwa ihhhmmmm_ii. trrtt   rifaaafe  naraaaatT� g   \n",
      "('epoch', 91)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5977\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "snare. Words exist b saaeeihf ee i casiesssee  vgeei    saeessethgtt.es hhcaa s ssssgss  b     ecc e\n",
      "('epoch', 92)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5214\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " have gotten the rabnigguuyuuuaaa isgg.tteieieeinn cce  ee es eeeee oonho  ee   eaeae. hhh.naga.eaaa\n",
      "('epoch', 93)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.4905\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ten the fish you can ffg ge     rr...e hydyhwaahhhaaffte iiiiiI   c       ee tt  Wh taehhhhhag eaaai\n",
      "('epoch', 94)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5068\n",
      "('\\n\\ttemperature:', 1.0)\n",
      ". The rabbit snare e iissgseeeu u  s eeeeea eeseeemeeb aeeeeeese e s eeess s s eea ee aefeeeasaaesss\n",
      "('epoch', 95)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5478\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "you have gotten the mi ni  uyya   a f oogtot nnhnneee.c.vh yyyy Wffffe ettntt   nnc yc    a  aooo oe\n",
      "('epoch', 96)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5902\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " exist because of meee  s.i n   cyhhaao eettetthnhrr I   ue eba brrraifawhggms.bscRv�av     r ogge e\n",
      "('epoch', 97)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.2814\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "bit, you can forget  tm rn.r...uWyreyuaaaaaaoggge emIiaee  c   yWuuoaaoatt.ggahhtmrei    y  g     rn\n",
      "('epoch', 98)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.2110\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ause of meaning. Onccncuuuaaae tttttnn .ehri h  b adbafff tg  g itv     c c aaaaahtgtgnn nnh.or  s  \n",
      "('epoch', 99)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1929\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "he rabbit, you can fgagg    e rn..o. aocoooauaaaogott r rrrrrr     rahaIaahwwiiiigthhtr         t   \n",
      "('epoch', 100)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1915\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "because of meaning.  n c cuuuaaae etttt    rhmiiss.    aaawhahvggte eethh        ng eosg ev ngghhhoW\n",
      "('epoch', 101)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1757\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " because of the fishi  ccccyuy vgvgt  e n ..rrhmngngngaaaao tt  aaoa.utn     rawar.   r ewafhhhhhiri\n",
      "('epoch', 102)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.2133\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "rabbit. Once you havvgggtttn gheimiin  gouyu oaf  t  ft ohhmmmrrhhcdthwutyrirt.haarr rhirradrir r   \n",
      "('epoch', 103)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.2465\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ause of the rabbit. cccchy afvsgggggtt .r..  3cc . yha ofotgtt    .   rr  hy aaoagggnnhhwiiiinrr ccc\n",
      "('epoch', 104)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.3637\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "it. Once you have got tnnhhemminn gg hWunayff naaafoh o nrn           oahauaaggggggghhhhhr       .W \n",
      "('epoch', 105)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5537\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "en the meaning, you fane  ate t e  mmyWfcuogaa.ognohatttar  r      hyyds baaigghahhhiih eeee ee    e\n",
      "('epoch', 106)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.7817\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "cause of meaning. On eccyuhyaa  f tttt  nn.rnr r..uhyadIbuaaaaaIaiggtiiiiggiir   ccucycf       ttg  \n",
      "('epoch', 107)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.6611\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "can forget the snare. Wy ro   as sb e  eemhhhihhhc7ce ignaggvvvv     .outo agtgggggghgg rrrry..... .\n",
      "('epoch', 108)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.4928\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "t the trap. The rabbaa  aaat   iisshseee .toccufffaeaaea.e.. .y. uc  ss sss g gt e  hhWaaaa au awhwa\n",
      "('epoch', 109)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.3294\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ing. Once you have gttttn hhemaainigg uy  f     gv ttn hhiihhhhhhhhgttaf   vvgv        aaahhihgggggh\n",
      "('epoch', 110)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.3850\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " find a man who has f fggottt  rr      c . .yraawwwah whhhhtg g irrr n   r     WWuWiaaaaoanwwiaamgme\n",
      "('epoch', 111)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.4569\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e of the rabbit. Oncyhyga vfggtttttn nhrmrroohtadaaaaawahaaaaaaar sNc erM    s     dehhaaaaghhhhhwgf\n",
      "('epoch', 112)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.8076\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "abbit. Once you haveggggtttt  ern  iiee  h yuyauuo fftttteei ii  e     c b eeeettttngg t   iese e e \n",
      "('epoch', 113)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.6759\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " the meaning, you can  oaoeeoeoiehmheo.WWhreu u efnianas.IeIi  uiouffcucsuee gohoihh.hh.Whuu uffwvv \n",
      "('epoch', 114)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.0874\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " because of meaning.i nhcccouuaaaf   tttt    .rr   .utwwaaaawhhggawannr rrrr  r    s.ouWwarwawwfhhgh\n",
      "('epoch', 115)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.4000\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e of the rabbit. OncyWy   gfgvgggttt nhrnmhhuWWutoWey awhwiaiiIimmaaaeeer    o  ffaawosa  gahhhh.ehc\n",
      "('epoch', 116)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.2137\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "aning, you can forge tt   nnrr.eWWhyaeygwowuwaaaaa.eimeeeeirriii ses ee oa  e f tteea . g ahanwa hy \n",
      "('epoch', 117)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1663\n",
      "('\\n\\ttemperature:', 1.0)\n",
      ". Once you have gottt nhhemmainiggueya ayn   aag    eeeer hnhohnhiohhhab  f v              ihnngguhi\n",
      "('epoch', 118)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1459\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e rabbit. Once you h vvgggtttn hhehaintnt tyy  f     g  faaaahoihhtfgthtt tcc           . raooooooav\n",
      "('epoch', 119)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1354\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "use of the rabbit. Occyhy  fvfvggggttt  urmnhut t t.WWyaawhwawwnaaaaagaemrrrr   rt.   uddaaaaaaaahwa\n",
      "('epoch', 120)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1165\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "bbit, you can forget  te nnrr..Whhyae  nwaaaaabvgt iiin aht  ssvgggoot t  ai ia eee hhhoaawg n  n  g\n",
      "('epoch', 121)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1243\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "p exists because of tee easaiin c  uhyfeeeseeee   hhhi ae eaa  e ahnn   iu .  . tag n  aghhntnttgtto\n",
      "('epoch', 122)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1171\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "here can I find a ma  ooooaaaffvgggtthtrrrrrd c 2 sehhaaaaaaIoigghhisss   sec c acteeeeeaae ee nrohu\n",
      "('epoch', 123)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1281\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "trap. The rabbit snaa  t i ssv ee uuccf nhgeeeeaegginnn..hfn    eeefeo   ttg  aahhbuu uyahwwwa ti   \n",
      "('epoch', 124)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1252\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "you can forget the wrrr..hhhyrrbbaarIaaiav    :liv:sssfag  tnghhh e eeaaccc hna      g.n. ..eohn ahn\n",
      "('epoch', 125)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1452\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "as forgotten words s  hyaaIIbaawhhffeei nn 4O�t e ccv ff otaatnt aoto .et.chaus aahaa utgtg.   ssss \n",
      "('epoch', 126)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1430\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "because of meaning.    c cauufaoe  ttt hnnr.rr  yyyI wwaaawfaaggihhiiiigtr c cg  ggggggtt hwwuoe..oo\n",
      "('epoch', 127)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1259\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "en words so that I maghhfee h awrrwwaatt  c  .Iniirii rr waohoaag af fgfhihrrrrr h dWcccccc  Iiaaigg\n",
      "('epoch', 128)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1220\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "u have gotten the fiin gg yya  afng  f ttgh mnnrotocfachhnn .  aahorrh..     fgn nr   avtttththtuaaa\n",
      "('epoch', 129)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1093\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e words. Where can Iaiiif e mmi oooofaff   faoawaW.rrr ycccfht.5rarrrhiirrr.e.y  aK�avavvvffao t  ih\n",
      "('epoch', 130)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0933\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "nce you have gotten hheamain gg ayu ff     tf  fn..nrnufffnhuaa fa   t f c   c    ttfthwtotonthnheaw\n",
      "('epoch', 131)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0995\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "here can I find a ma  ouooaaaaffgggtthtrrnr  r cccyyWyraaaawahhhnenermmsIks    r    uaaaaaaeghhhhhhh\n",
      "('epoch', 132)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0985\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ords exist because off eeeies.i n c cuhy feeeee  tnn nhhiii   e   oaafff v  ttnowgoho.yc cannnwwathr\n",
      "('epoch', 133)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1133\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "has forgotten words  c hyaaIIbaaghigge hnnis|  v e    y fet ffiegggggghhhhd  ff   n  y       ngaffgg\n",
      "('epoch', 134)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1173\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "you can forget the wnnre.WWhyde eanauahaaaaaemei g.ss  s ssssss efeeeeeaaeaeaaaaaa s  eessssssssssss\n",
      "('epoch', 135)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0988\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "an I find a man who aaahffgggtttt   r r c cchhyhraaawhhhhhrr. r  cUvr        aagghhhhhggwhhhhait    \n",
      "('epoch', 136)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0818\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ere can I find a man oooofaafffgggtttoe.rhhyd cccyyyy afffg i   n .ei.ir ccc fggfaaotttttteoe.e.Wcc \n",
      "('epoch', 137)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0870\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " of meaning. Once youaaaae  ttttn hhemm   c   wa  aaannnafhnhhhht r t cccfcc      irwtt e...eoohmhhh\n",
      "('epoch', 138)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1376\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e. Words exist becauaeihf  eee  ss  ny  ccc fae eeeeee n   ...hyseee ee onaanttgg s aee  uuayeuuoo .\n",
      "('epoch', 139)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1516\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "bit, you can forget  te nnr...Whhhdou anaaoaoggtt eiiiirne . ydyyoooottttgafeeg ieerrraryee eeeee Wa\n",
      "('epoch', 140)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5345\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "eaning. Once you hav af    nnhhsiiinn t oufhufff gcu ofaWwy     WcWeh.rahxLeniihhhhmsnssv     c     \n",
      "('epoch', 141)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.4514\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "nce you have gotten hhenrann gghhyannenn  oavtt   i  ooaogahhwwaawhh   nrrurr   rrrrrr rhhwwaiaawaaa\n",
      "('epoch', 142)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1834\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e rabbit. Once you h vvgggtttt  uemmiIneeeeuue       ff eeeee.gemggegnuv  f eeee.eceeeee gnevf eee.e\n",
      "('epoch', 143)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1997\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " words so that I mayIheaec  Wtr\n",
      "owhhhtri in...hdIr0   vvvgvvttgo gfghfhhfgfggegeyW..   .   cWWyee.s \n",
      "('epoch', 144)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.7943\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "that I may have a worrwwhhhiii  igmrrirogir      hhoWdoog9gwhhhnhhhiIrihhh                  nhhhh4hh\n",
      "('epoch', 145)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5418\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e rabbit. Once you h vogvgtfttt�hehmmhnnggy  yyya  vnniaft ttiehieniahavuacyya oogegee i eienrrer uu\n",
      "('epoch', 146)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5094\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "sh you can forget th nhrr....hhyuoy an vvvvgtt   mimahhhhggggggawwhfttfr     ....Crrr y yafhhhnnt t \n",
      "('epoch', 147)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5190\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "at I may have a worduwhwhiiii ggah�aiigi  g gte. mc tg  tttthanoe ttuo.wyWwa  a  aIIeIaemeemmh0ewouo\n",
      "('epoch', 148)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.2647\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e rabbit. Once you h vvggttttn .hemmiignggeyy   fftt aatt oeeeeehhWh yya� abaa sesggiiiiime 4eeee ee\n",
      "('epoch', 149)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1407\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "se of the fish. Oncecyyy  gvgggggtt tthehenhhnei.huyy f  fvgvgvvtgtt immhhuhatgogogoywffhtt      ...\n",
      "('epoch', 150)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1049\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " meaning. Once you haoo ttttt nyhemmrrr aaun  IawhhiaduaaoNt twhhhr i eeim  rirriamv nghoo aaafhffaf\n",
      "('epoch', 151)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1099\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e you have gotten themmien gg hyue aan taaatohh nniig. cyhr        f ttttnhhitgawhhhhuhya       u   \n",
      "('epoch', 152)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1058\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "he rabbit snare exisssgae  uf  f  eee ea  nughhhuhhngeeegtn hn     iiv   ee anfhngwIhggthgnga    c. \n",
      "('epoch', 153)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0946\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "s because of the rabei n c cyhy f v gg tttit  hhinhhthgayya     n v     r rmehhghhhggggwhhhwavf v   \n",
      "('epoch', 154)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1013\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " the snare. Words exas  b saaeehhf  ee i.eii  asggv  fotetttte  hcvcehhhyyubbb  .hhn ynfv giiivgvtnt\n",
      "('epoch', 155)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0938\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "gotten the fish you yaofffvgvg  eeihnrrr  y  tgnnafe afhaaghhhhaEuuccc             rrrreohgggghhghhh\n",
      "('epoch', 156)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0750\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ning. Once you have tttttn uhemmanni g u   aahn neaaoafnhhhhht    aycc     t    nghhhoetooghghhwhhn \n",
      "('epoch', 157)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0684\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e rabbit snare existsgseeeu    e eee  aeeeeeeghhhhgegegee  ees gv vvvneeee  gageeghggggggeegeeh   ee\n",
      "('epoch', 158)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0814\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ave gotten the rabbieguhyu aafifisgge eenii   c c   ee ogoeottnangohhgge  a huya f.cc r  teehi n rr \n",
      "('epoch', 159)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0976\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "fish trap exists becccs aoottee aas ri     aaaIeee � oghghhhhho  eoeagh u        ihge.a. nihwhhhhhhh\n",
      "('epoch', 160)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1007\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "tten the meaning, yo  aanftoaoeuttt  or.  c y ra IbIaawhhigthhhhizfti      v   g v  fffgghnighgahhht\n",
      "('epoch', 161)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0950\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " find a man who has ffgggtttt  rr    ccr.ueyy aawhiahhhhr.ae eeii c     vvvvg egg tthhhhhhggggttuny \n",
      "('epoch', 162)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0678\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "can I find a man whouaaaaffgggttht  rr     yccyhyaaaiwwhgghhhh r. i           v  tgvtggfgghghhhhghgw\n",
      "('epoch', 163)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0818\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "forget the words. WhydebeaIaIeiifs e ii    v feffggggegttthhhht c  ccWcy b        e  hW.emhhghgghggg\n",
      "('epoch', 164)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0782\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "man who has forgottet  in    c hyaeya ooghhngnhhh ie nerrhy g  f    nwaaaffghnhhthhhhht   cc      v \n",
      "('epoch', 165)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0695\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "use of the rabbit. Occuhy ffvsvvgggttt   ri ha gg geuy awwhhhf n  tteheeii      cuaaag egtst nnhhhhr\n",
      "('epoch', 166)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0611\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "the words. Where canaIahrf  e mm  U..   fwcraahaaaahgttt htrr  sc      r aaaiaaahhheuhhhhhhv. sc c+v\n",
      "('epoch', 167)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0843\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "sh trap exists becaus aog tee aasei n   chyuee ee eeetnhhhmmiieeeegugeef     naoeeeee uun nhhhhhu  e\n",
      "('epoch', 168)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0852\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " gotten the rabbit, hyub aa fvsgge ite iimi .ccaeeeu ga otf  t   cueeegrthhwywhhhwhhhaeeefr   vii   \n",
      "('epoch', 169)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0935\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "en the meaning, you aan noaoe ttt  mmrre .Wahr I wIawwwwaaaairriiwhfirrrrrr   c  g   rchaaafggvhhhth\n",
      "('epoch', 170)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0738\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "abbit. Once you haveggttttn hhemmiin .g yy   ffnvaaafttttthhhhh. cc.  yyyys   vvvtttheneheeeembhnigg\n",
      "('epoch', 171)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0787\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "y have a word with hii mgaghhifggh    n  tt        tnnahaaawaagghhgwhhfu                  hggeggaann\n",
      "('epoch', 172)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.2422\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "have gotten the rabbigg hyI uya  v g ggt nhiiihimgthggutt          th.  Wgwwgghhhhhhhh   tiir       \n",
      "('epoch', 173)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5140\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "he fish you can forgee eeennrrre. hhydeeseadbfafaa eiiiee eeseee y u eteeees esseeeenmiieeeeese e   \n",
      "('epoch', 174)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.6744\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ts because of the ras   n n chh  n   gf tntttn   nnnttn  cyau ooaatfaoaofenn    e          u ofahnnn\n",
      "('epoch', 175)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.6176\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ten the fish you canffafgveh eem�rruuW y   geeIIeeehhhhemhhmhaffbse ssv iiirtsgcv gaaaaeeeof  Wesuou\n",
      "('epoch', 176)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1869\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " has forgotten words  cc.haauraaaehrrged   r e .rs    vahgghhhfgtfgegvhnn   t  vv     t  nfffhhwwhhg\n",
      "('epoch', 177)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.8763\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ho has forgotten wor r    haf|IIaaawh5ognhihtt swttt(  r yy.   ruahswaaahiigieinhi�2ssFTo.c  teeee e\n",
      "('epoch', 178)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.5475\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "n the fish you can fatg g  eernrrno. nW..oooaobeIaaaaoett.e raaa i.se   sbees.svaeeeteetefsea es  es\n",
      "('epoch', 179)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1786\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "abbit, you can forge    e rrrre..hhyieoawhhaaaaffggg   e  r r c   cc0ttwhmowhhghtoette.rrrrrihrr   a\n",
      "('epoch', 180)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1253\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "the trap. The rabbit  oaogat iigsg e  eenr  Weetteuuuongggeaainieeeeend eu u ee e eeeeeetggggmeggeeg\n",
      "('epoch', 181)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0917\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " Where can I find a mi. ooo.aaaafffggttht  r   .   ccccyyaaawgggnntt   .eer  r .  oaaaangggtaaghhg  \n",
      "('epoch', 182)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0855\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "s forgotten words so rhawuIaaahhhIeeci airrrrar.  h io W.aaaafaaaagthh h m        s    r ghhhhhghhhh\n",
      "('epoch', 183)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0810\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "et the snare. Words e as eb aaaeehhffeuesceais  cc fv c ff e eei eto.e  ne.c  geeee ge gtntnte eneee\n",
      "('epoch', 184)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0727\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " can forget the trap...hh rebb r   a o  gt  iggg ghhnntohuttttat        Wh r uabaaggWhhtahhiiiiii  .\n",
      "('epoch', 185)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0801\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ng, you can forget tt  nnrne..Whyhy  awaaaaao  g  2siiitr r�c .out.fgceu oaaahthr   nt ..h rr   rrai\n",
      "('epoch', 186)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0849\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ve gotten the rabbitg hyu bayafisgge   riiaiiee  ccuuuaoaavgg gtteen rrmmm B.eeuaou  uawwawhhngeeeea\n",
      "('epoch', 187)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0750\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "bbit. Once you have ggtttn uhemmiinigg yyyaaaannfaaf tt  riii v  Wc c  aaaaggtttgnnnere ...   yyyy u\n",
      "('epoch', 188)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0656\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "use of meaning. Once cuuaaaoe  tttt  .r rra    ubwaaaaahgaihiithhiii  e  e c ggvgggttttnnmohno..tm e\n",
      "('epoch', 189)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0702\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " have gotten the fisn gguWya fff gvu   ete. nn cc cnnngnngoeggtttooe.ooaau. yy  yybIaaIe aI ie ieihi\n",
      "('epoch', 190)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0818\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ause of the rabbit. cccyhy sf sv gggtt e ere  us getWWy angegeaeh eeeeeme  uuueeees  eeeeeenehmieeee\n",
      "('epoch', 191)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0794\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "t the snare. Words eeas eb aaseeIIff  sssse s  cuaafW c eaaaaaen hr..  .n..is   savavggttttggge bhte\n",
      "('epoch', 192)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0701\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " meaning. Once you haae  ttttn hhehmiai c awaa  a ii   t  t oirh tthtttnhwwwhhwha  ra  raar rirrrrrr\n",
      "('epoch', 193)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0794\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "he rabbit snare exisssgse  ub  f  eee  aaaccnhhinnh ege.. .  ..     f gsggggtttttttnhhuWcnWuyyye a  \n",
      "('epoch', 194)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0696\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "Words exist because hf  e eies.i n cucnn  ofeeeee tttoe.eoohhdueeeeeeaebeeeeaai  eeegees seseeee yue\n",
      "('epoch', 195)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0628\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "he fish trap exists  ccccs aoottteiea.re....  ruu bb e a   gttthhiiii   ogtthh gggg tt  nhhhy    .t.\n",
      "('epoch', 196)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0859\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "s. Where can I find e m   ono.aaaafftgghohhhht      c   F       nggnnnnnrghhnhnootoff  aaa      r h \n",
      "('epoch', 197)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1051\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e rabbit, you can fosg     e rrre..cWhcu hwhhhaffo ggt rrrrn       yWhhhaaaaaagghhhhhii i    c      \n",
      "('epoch', 198)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0796\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "you have gotten the main gg hy   aan noaa tth nnrhtt. .aoh  yafa aa  g gt   i hr cc.t thttttghhn nrt\n",
      "('epoch', 199)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0740\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ap. The rabbit snare   iissgsee uau vofotteeeaeeeeemmiihd  deee u fffooamtgigeggnuhehyc yauot c ne t\n",
      "('epoch', 200)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0963\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "who has forgotten wor      hraeIIeaaghhhihhhhhiro fa v        i   faWhfggggwnhhhgtntt  .  8      r  \n",
      "('epoch', 201)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0837\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "abbit. Once you havegggtttn nhemmainigg Wyy aaaoaaaat tt nnmeii     uc ooaaaaaatttnhnnnrrrr       y \n",
      "('epoch', 202)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0793\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "eaning, you can forgetttt  nrrr...hhyrr buaaawaaa  tt iiiiiie    rc.oaff.fggtt nghhttr   c   yryrth \n",
      "('epoch', 203)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0705\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ho has forgotten wor      hdaaIIaaahhhwgnhhhiirthdav            fgaggggghtnhhohnhtt.c  . c         t\n",
      "('epoch', 204)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0770\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "have gotten the meanigg hyu   an noaee t  nimmnhtoWanuu  giaataawtr Iar.hmet    rrrraaaaa t iwawhhhi\n",
      "('epoch', 205)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0701\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "you can forget the srrre.uWhydebbaaa bfbaea.iIiI  ssv  e egesegtfafhheeegggeueuec     vise nn nggggo\n",
      "('epoch', 206)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0740\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e exists because of eee eas i n c cuWyfeeeeee tnnn nriae e eee  aaaaaaao  eggsge...       ahneeggggg\n",
      "('epoch', 207)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0759\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "e of the fish. Once yu  fgvgggggttn nhehhut   tW.Wy  ann iiiIaange e mota f n   t uo goowwaotnfhwhhh\n",
      "('epoch', 208)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0498\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "you have gotten the main gg hyab fan  ota tth  r    t ohhaaarwaahhhhhhhhri    q rr         ngfhhhhtg\n",
      "('epoch', 209)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0608\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ing. Once you have gttttn hhemmaanigg yy  rn n aaaa  t hhhhhahaat      hr         o�whhhhhiighwhhhhh\n",
      "('epoch', 210)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0614\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "p. The rabbit snare t ii stsee uab ooogget eaase.em  nrdrynee ss ee oaahaffh eee eausu        v aeeg\n",
      "('epoch', 211)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0651\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "I find a man who hasaf gggtttt  rr   c cyh.yyraaaahvihnnnhhiii ii c   t     gggttttt oohwhwhhhaWyyya\n",
      "('epoch', 212)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0674\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " you have gotten thehmianigguhya  fangv  t     rirmohf tgggwawwnuhaaaah   t.  rriir       hhgaogaffg\n",
      "('epoch', 213)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0810\n",
      "('\\n\\ttemperature:', 1.0)\n",
      " you can forget the nrrr...hhyrbbbaa aaaa   gt  i see.  .  .ahhhaonhefeettntt        bgsebe aaawwhhW\n",
      "('epoch', 214)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0927\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ecause of the rabbitn cccyuy a vsgo  ttt ..hnimmh n  uuna  ttttfffhhnghhauyurw            Immmhigggg\n",
      "('epoch', 215)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.0738\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "ho has forgotten wor      a aaIIaaahhhhghhhhri rrrrr        rriiihaaiaghnhhhhhgvvg    c        i tgg\n",
      "('epoch', 216)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.1138\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "hat I may have a woriwwhhhhiii ggawghihg i  vgve  gc  n   ngggngggggooaooaaaao uu       r  r   ahhha\n",
      "('epoch', 217)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 0.7505\n",
      "('\\n\\ttemperature:', 1.0)\n",
      "bit. Once you have ggtttn hhehminn ng hy    rn  n h hhunhinhhwhhhnhnn  i             t tthnnhnhh.ehh\n",
      "('epoch', 218)\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s - loss: 1.1498\n",
      "('\\n\\ttemperature:', 1.0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "sum(pvals[:-1]) > 1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-03c2f2d28da2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#[0.2, 0.5, 1., 1.2]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\ttemperature:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-adb8a52790c8>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(temperature, seed, predicate)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# sample the character to use based on the predicted probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnext_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-adb8a52790c8>\u001b[0m in \u001b[0;36msample\u001b[0;34m(probs, temperature)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.multinomial (numpy/random/mtrand/mtrand.c:32793)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: sum(pvals[:-1]) > 1.0"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    print('epoch', i)\n",
    "\n",
    "    # set nb_epoch to 1 since we're iterating manually\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    # preview\n",
    "    for temp in [1.0]: #[0.2, 0.5, 1., 1.2]:\n",
    "        print('\\n\\ttemperature:', temp)\n",
    "        print(generate(temperature=temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about all there is to it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
