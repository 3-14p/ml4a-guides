{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning / fine-tuning\n",
    "\n",
    "This tutorial will guide you through the process of using _transfer learning_ to learn an accurate image classifier from a small number of training samples. Generally speaking, transfer learning refers to the process of leveraging the knowledge learned in one model for the training of another model. \n",
    "\n",
    "More specifically, the process involves taking an existing neural network which was previously trained to good performance on a larger dataset, and using it as the basis for a new model which leverages that previous model's accuracy for a new task. Another name for this procedure is called \"fine-tuning\" because we will take a previous neural network and fine-tune its weights to the new dataset and task. This method has become extremely popular in recent years to improve the performance of a neural net trained on a small dataset. The intuition is that the new dataset may be too small to achieve good performance itself, but we know that most neural nets trained to learn image features often learn similar features anyway, especially at early layers. This has been largely enabled by the open-sourcing of state-of-the-art models; for the top performing models in image classification, it is common practice now to not only publish the architecture, but to release the weights of the model as well. This lets amateurs use top image classifiers to boost the performance of their own task-specific models.\n",
    "\n",
    "This guide will go through the process of loading a state-of-the-art, 1000-class image classifier, [VGG16](https://arxiv.org/pdf/1409.1556.pdf) which [won the ImageNet challenge in 2014](http://www.robots.ox.ac.uk/~vgg/research/very_deep/), and using it to train a smaller custom classifier on our own images.\n",
    "\n",
    "How it works: we will first load VGG16 and remove its final layer, the 1000-neuron softmax classification layer specific to ImageNet, and replace it with a new classification layer for the classes we are training over. We will then \"freeze\" all the weights in the network except the new ones connecting to the new classification layer, and then re-train the model on our new dataset. By keeping the earlier weights fixed, we get to use the features that were discoverd in the previous model.\n",
    "\n",
    "We will also compare this method to training a small neural network from scratch on the new dataset, and as we shall see, it will dramatically improve our accuracy. We will do that part first.\n",
    "\n",
    "This guide requires you to install [keras](http://www.keras.io), if you have not done so already. It is highly recommended to make sure you are using the GPU to train these models, as it will otherwise take much longer to train (however it is still possible to use CPU). If you can use GPU and have Theano as your backend, you should run the following command _before_ importing keras, to ensure it uses the GPU.\n",
    "\n",
    "    os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "    \n",
    "If you are using Tensorflow as the backend, this is unnecessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is going to be to load our data. As our example, we will be using the dataset [CalTech-101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/), which contains around 9000 labeled images belonging to 101 object categories. However, we will exclude 5 of the categories which have the most images. This is in order to keep the class distribution fairly balanced (around 50-100) and constrained to a smaller number of images, around 6000. \n",
    "\n",
    "If you wish to use your own dataset, it should be aranged in the same fashion to `101_ObjectCategories` with all of the images organized into subfolders, one for each class. In this case, the following cell should load your custom dataset correctly by just replacing `root` with your folder. If you have an alternate structure, you just need to make sure that you load the list `data` where every element is a dict where `x` is the data (a 1-d numpy array) and `y` is the label (an integer). Use the helper function `get_image(path)` to load the image correctly into the array, and note also that the images are being resized to 224x224. This is necessary because the input to VGG16 is a 224x224 RGB image. You do not need to resize them on your hard drive, as that is being done in the code below.\n",
    "\n",
    "If you have `101_ObjectCategories` in your data folder, the following cell should load all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading 6209 images from 97 categories\n",
      "train / validation / test split: 4346, 931, 932\n",
      "('training data shape: ', (4346, 224, 224, 3))\n",
      "('training labels shape: ', (4346, 97))\n"
     ]
    }
   ],
   "source": [
    "root = '../data/101_ObjectCategories'\n",
    "exclude = ['BACKGROUND_Google', 'Motorbikes', 'airplanes', 'Faces_easy', 'Faces']\n",
    "train_split, val_split = 0.7, 0.15\n",
    "\n",
    "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "categories = [c for c in categories \n",
    "              if c not in [os.path.join(root, e) for e in exclude]]\n",
    "\n",
    "# helper function to load image and return it and input vector\n",
    "def get_image(path):\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x\n",
    "\n",
    "# load all the images from root folder\n",
    "data = []\n",
    "for c, category in enumerate(categories):\n",
    "    images = [os.path.join(dp, f) for dp, dn, filenames \n",
    "              in os.walk(category) for f in filenames \n",
    "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "    for img_path in images:\n",
    "        img, x = get_image(img_path)\n",
    "        data.append({'x':np.array(x[0]), 'y':c})\n",
    "\n",
    "# count the number of classes\n",
    "num_classes = len(categories)\n",
    "\n",
    "# randomize the data order\n",
    "random.shuffle(data)\n",
    "\n",
    "# create training / validation / test split (70%, 15%, 15%)\n",
    "idx_val = int(train_split * len(data))\n",
    "idx_test = int((train_split + val_split) * len(data))\n",
    "train = data[:idx_val]\n",
    "val = data[idx_val:idx_test]\n",
    "test = data[idx_test:]\n",
    "\n",
    "# separate data for labels\n",
    "x_train, y_train = np.array([t[\"x\"] for t in train]), [t[\"y\"] for t in train]\n",
    "x_val, y_val = np.array([t[\"x\"] for t in val]), [t[\"y\"] for t in val]\n",
    "x_test, y_test = np.array([t[\"x\"] for t in test]), [t[\"y\"] for t in test]\n",
    "\n",
    "# normalize data\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_val = x_val.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# convert labels to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# summary\n",
    "print(\"finished loading %d images from %d categories\"%(len(data), num_classes))\n",
    "print(\"train / validation / test split: %d, %d, %d\"%(len(x_train), len(x_val), len(x_test)))\n",
    "print(\"training data shape: \", x_train.shape)\n",
    "print(\"training labels shape: \", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything worked properly, you should have loaded a bunch of images, and split them into three sets: `train`, `val`, and `test`. The shape of the training data should be (`n`, 224, 224, 3) where `n` is the size of your training set, and the labels should be (`n`, `c`) where `c` is the number of classes (97 in the case of `101_ObjectCategories`. \n",
    "\n",
    "Notice that we divided all the data into three subsets -- a training set `train`, a validation set `val`, and a test set `test`. The reason for this is to properly evaluate the accuracy of our classifier. During training, the optimizer uses the validation set to evaluate its internal performance, in order to determine the gradient. The `test` set is always held out from the training algorithm, to avoid overfitting, and is only used at the end to evaluate the final accuracy of our model.\n",
    "\n",
    "Let's quickly look at a few sample images from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "555555555\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing the transfer learning, let's first build a neural network from scratch for doing classification on our dataset. This will give us a baseline to compare to our fine-tuned network later.\n",
    "\n",
    "The network we will construct contains 4 alternating convolutional and max-pooling layers, followed by a [dropout](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) after every other conv/pooling pair. After the last pooling layer, we will attach a fully-connected layer with 256 neurons, another dropout layer, then finally a softmax classification layer for our classes.\n",
    "\n",
    "Our loss function will be, as usual, `categorical_crossentropy` loss, and our learning algorithm will be adadelta. Various things about this network can be changed to get better performance, perhaps using a larger network or a different optimizer will help, but for the purposes of this notebook, the goal is to just get an understanding of an approximate baseline for comparison's sake, and so it isn't neccessary to spend much time trying to optimize this network.\n",
    "\n",
    "Upon compiling the network, let's run `model.summary()` to get a snapshot of its layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 52, 52, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 97)                24929     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 97)                0         \n",
      "=================================================================\n",
      "Total params: 1,233,473.0\n",
      "Trainable params: 1,233,473.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model to use categorical cross-entropy loss function and adadelta optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a medium-sized network with ~1.2 million weights and biases (the parameters). Most of them are leading into the one pre-softmax fully-connected layer \"dense_5\".\n",
    "\n",
    "We can now go ahead and train our model for 100 epochs with a batch size of 128. We'll also record its history so we can plot the loss over time later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4346 samples, validate on 931 samples\n",
      "Epoch 1/100\n",
      "4346/4346 [==============================] - 38s - loss: 4.5407 - acc: 0.0308 - val_loss: 4.4815 - val_acc: 0.0602\n",
      "Epoch 2/100\n",
      "4346/4346 [==============================] - 38s - loss: 4.4150 - acc: 0.0686 - val_loss: 4.3017 - val_acc: 0.0945\n",
      "Epoch 3/100\n",
      "4346/4346 [==============================] - 38s - loss: 4.2222 - acc: 0.1086 - val_loss: 4.0468 - val_acc: 0.1557\n",
      "Epoch 4/100\n",
      "4346/4346 [==============================] - 38s - loss: 3.9835 - acc: 0.1484 - val_loss: 3.7900 - val_acc: 0.1976\n",
      "Epoch 5/100\n",
      "4346/4346 [==============================] - 38s - loss: 3.7314 - acc: 0.1855 - val_loss: 3.6591 - val_acc: 0.2578\n",
      "Epoch 6/100\n",
      "4346/4346 [==============================] - 38s - loss: 3.5076 - acc: 0.2209 - val_loss: 3.4835 - val_acc: 0.2460\n",
      "Epoch 7/100\n",
      "4346/4346 [==============================] - 38s - loss: 3.2847 - acc: 0.2630 - val_loss: 3.2689 - val_acc: 0.2997\n",
      "Epoch 8/100\n",
      "4346/4346 [==============================] - 38s - loss: 3.0013 - acc: 0.3118 - val_loss: 3.1930 - val_acc: 0.3244\n",
      "Epoch 9/100\n",
      "4346/4346 [==============================] - 38s - loss: 2.7695 - acc: 0.3583 - val_loss: 2.9774 - val_acc: 0.3416\n",
      "Epoch 10/100\n",
      "4346/4346 [==============================] - 38s - loss: 2.5365 - acc: 0.3983 - val_loss: 2.8194 - val_acc: 0.3695\n",
      "Epoch 11/100\n",
      "4346/4346 [==============================] - 38s - loss: 2.3103 - acc: 0.4459 - val_loss: 2.7380 - val_acc: 0.3813\n",
      "Epoch 12/100\n",
      "4346/4346 [==============================] - 38s - loss: 2.1475 - acc: 0.4795 - val_loss: 2.6909 - val_acc: 0.3953\n",
      "Epoch 13/100\n",
      "4346/4346 [==============================] - 38s - loss: 1.8565 - acc: 0.5377 - val_loss: 2.7421 - val_acc: 0.3921\n",
      "Epoch 14/100\n",
      "4346/4346 [==============================] - 38s - loss: 1.6818 - acc: 0.5658 - val_loss: 2.5981 - val_acc: 0.4393\n",
      "Epoch 15/100\n",
      "4346/4346 [==============================] - 38s - loss: 1.5412 - acc: 0.6045 - val_loss: 2.5592 - val_acc: 0.4382\n",
      "Epoch 16/100\n",
      "4346/4346 [==============================] - 38s - loss: 1.3512 - acc: 0.6401 - val_loss: 2.6747 - val_acc: 0.4339\n",
      "Epoch 17/100\n",
      "4346/4346 [==============================] - 38s - loss: 1.2114 - acc: 0.6723 - val_loss: 2.6503 - val_acc: 0.4318\n",
      "Epoch 18/100\n",
      "4346/4346 [==============================] - 38s - loss: 1.0976 - acc: 0.7018 - val_loss: 2.6322 - val_acc: 0.4404\n",
      "Epoch 19/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.9964 - acc: 0.7260 - val_loss: 2.6771 - val_acc: 0.4479\n",
      "Epoch 20/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.9172 - acc: 0.7483 - val_loss: 2.6750 - val_acc: 0.4468\n",
      "Epoch 21/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.8427 - acc: 0.7655 - val_loss: 2.6560 - val_acc: 0.4726\n",
      "Epoch 22/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.7785 - acc: 0.7754 - val_loss: 2.7327 - val_acc: 0.4576\n",
      "Epoch 23/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.7053 - acc: 0.7977 - val_loss: 2.8198 - val_acc: 0.4533\n",
      "Epoch 24/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.6925 - acc: 0.7994 - val_loss: 2.7577 - val_acc: 0.4597\n",
      "Epoch 25/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.6092 - acc: 0.8182 - val_loss: 2.8431 - val_acc: 0.4468\n",
      "Epoch 26/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.5661 - acc: 0.8378 - val_loss: 2.9029 - val_acc: 0.4576\n",
      "Epoch 27/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.5162 - acc: 0.8532 - val_loss: 2.9416 - val_acc: 0.4576\n",
      "Epoch 28/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.5112 - acc: 0.8458 - val_loss: 2.9678 - val_acc: 0.4586\n",
      "Epoch 29/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.4802 - acc: 0.8555 - val_loss: 2.9655 - val_acc: 0.4694\n",
      "Epoch 30/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.4321 - acc: 0.8714 - val_loss: 2.9573 - val_acc: 0.4683\n",
      "Epoch 31/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.4379 - acc: 0.8711 - val_loss: 3.0498 - val_acc: 0.4705\n",
      "Epoch 32/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.3906 - acc: 0.8840 - val_loss: 3.0571 - val_acc: 0.4629\n",
      "Epoch 33/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.3787 - acc: 0.8898 - val_loss: 3.0878 - val_acc: 0.4565\n",
      "Epoch 34/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.3744 - acc: 0.8863 - val_loss: 3.0943 - val_acc: 0.4748\n",
      "Epoch 35/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.3785 - acc: 0.8896 - val_loss: 3.0990 - val_acc: 0.4726\n",
      "Epoch 36/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.3520 - acc: 0.8951 - val_loss: 3.1261 - val_acc: 0.4608\n",
      "Epoch 37/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.3447 - acc: 0.8990 - val_loss: 3.0691 - val_acc: 0.4629\n",
      "Epoch 38/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.3292 - acc: 0.8992 - val_loss: 3.1341 - val_acc: 0.4672\n",
      "Epoch 39/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2945 - acc: 0.9144 - val_loss: 3.1678 - val_acc: 0.4651\n",
      "Epoch 40/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2834 - acc: 0.9096 - val_loss: 3.2061 - val_acc: 0.4662\n",
      "Epoch 41/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2829 - acc: 0.9160 - val_loss: 3.2115 - val_acc: 0.4769\n",
      "Epoch 42/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2608 - acc: 0.9241 - val_loss: 3.2818 - val_acc: 0.4705\n",
      "Epoch 43/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2643 - acc: 0.9213 - val_loss: 3.2121 - val_acc: 0.4726\n",
      "Epoch 44/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2493 - acc: 0.9225 - val_loss: 3.2950 - val_acc: 0.4651\n",
      "Epoch 45/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2611 - acc: 0.9236 - val_loss: 3.3133 - val_acc: 0.4715\n",
      "Epoch 46/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2246 - acc: 0.9301 - val_loss: 3.2911 - val_acc: 0.4694\n",
      "Epoch 47/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2414 - acc: 0.9268 - val_loss: 3.2376 - val_acc: 0.4769\n",
      "Epoch 48/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2282 - acc: 0.9340 - val_loss: 3.2864 - val_acc: 0.4780\n",
      "Epoch 49/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2262 - acc: 0.9296 - val_loss: 3.3845 - val_acc: 0.4758\n",
      "Epoch 50/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2009 - acc: 0.9406 - val_loss: 3.3347 - val_acc: 0.4769\n",
      "Epoch 51/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1928 - acc: 0.9409 - val_loss: 3.3904 - val_acc: 0.4855\n",
      "Epoch 52/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1862 - acc: 0.9443 - val_loss: 3.4426 - val_acc: 0.4812\n",
      "Epoch 53/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1973 - acc: 0.9402 - val_loss: 3.4805 - val_acc: 0.4705\n",
      "Epoch 54/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2090 - acc: 0.9390 - val_loss: 3.3708 - val_acc: 0.4780\n",
      "Epoch 55/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1750 - acc: 0.9443 - val_loss: 3.4272 - val_acc: 0.4694\n",
      "Epoch 56/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.2037 - acc: 0.9409 - val_loss: 3.4955 - val_acc: 0.4823\n",
      "Epoch 57/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1705 - acc: 0.9501 - val_loss: 3.5468 - val_acc: 0.4919\n",
      "Epoch 58/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1724 - acc: 0.9494 - val_loss: 3.4323 - val_acc: 0.4672\n",
      "Epoch 59/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1681 - acc: 0.9503 - val_loss: 3.5111 - val_acc: 0.4866\n",
      "Epoch 60/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1963 - acc: 0.9399 - val_loss: 3.4187 - val_acc: 0.4791\n",
      "Epoch 61/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1667 - acc: 0.9514 - val_loss: 3.5126 - val_acc: 0.4823\n",
      "Epoch 62/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1443 - acc: 0.9597 - val_loss: 3.5175 - val_acc: 0.4866\n",
      "Epoch 63/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1520 - acc: 0.9549 - val_loss: 3.4818 - val_acc: 0.4780\n",
      "Epoch 64/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1390 - acc: 0.9584 - val_loss: 3.6060 - val_acc: 0.4715\n",
      "Epoch 65/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1446 - acc: 0.9521 - val_loss: 3.4628 - val_acc: 0.4758\n",
      "Epoch 66/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1314 - acc: 0.9586 - val_loss: 3.5667 - val_acc: 0.4737\n",
      "Epoch 67/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1355 - acc: 0.9572 - val_loss: 3.5765 - val_acc: 0.4769\n",
      "Epoch 68/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1346 - acc: 0.9579 - val_loss: 3.5701 - val_acc: 0.4715\n",
      "Epoch 69/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1451 - acc: 0.9544 - val_loss: 3.5311 - val_acc: 0.4737\n",
      "Epoch 70/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1497 - acc: 0.9572 - val_loss: 3.6496 - val_acc: 0.4715\n",
      "Epoch 71/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1320 - acc: 0.9611 - val_loss: 3.5732 - val_acc: 0.4694\n",
      "Epoch 72/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1138 - acc: 0.9664 - val_loss: 3.6330 - val_acc: 0.4737\n",
      "Epoch 73/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1384 - acc: 0.9588 - val_loss: 3.6614 - val_acc: 0.4737\n",
      "Epoch 74/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1334 - acc: 0.9607 - val_loss: 3.6358 - val_acc: 0.4672\n",
      "Epoch 75/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1167 - acc: 0.9666 - val_loss: 3.6078 - val_acc: 0.4758\n",
      "Epoch 76/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1354 - acc: 0.9639 - val_loss: 3.6409 - val_acc: 0.4758\n",
      "Epoch 77/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1202 - acc: 0.9627 - val_loss: 3.5874 - val_acc: 0.4834\n",
      "Epoch 78/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1076 - acc: 0.9680 - val_loss: 3.7173 - val_acc: 0.4694\n",
      "Epoch 79/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1389 - acc: 0.9565 - val_loss: 3.5808 - val_acc: 0.4801\n",
      "Epoch 80/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1281 - acc: 0.9648 - val_loss: 3.6159 - val_acc: 0.4780\n",
      "Epoch 81/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1049 - acc: 0.9678 - val_loss: 3.6340 - val_acc: 0.4726\n",
      "Epoch 82/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1013 - acc: 0.9676 - val_loss: 3.6720 - val_acc: 0.4801\n",
      "Epoch 83/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0965 - acc: 0.9731 - val_loss: 3.7164 - val_acc: 0.4844\n",
      "Epoch 84/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0983 - acc: 0.9715 - val_loss: 3.7099 - val_acc: 0.4844\n",
      "Epoch 85/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1251 - acc: 0.9611 - val_loss: 3.6103 - val_acc: 0.4662\n",
      "Epoch 86/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0977 - acc: 0.9673 - val_loss: 3.5529 - val_acc: 0.4823\n",
      "Epoch 87/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0997 - acc: 0.9685 - val_loss: 3.7150 - val_acc: 0.4672\n",
      "Epoch 88/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0945 - acc: 0.9685 - val_loss: 3.8007 - val_acc: 0.4769\n",
      "Epoch 89/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1063 - acc: 0.9664 - val_loss: 3.8063 - val_acc: 0.4748\n",
      "Epoch 90/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1029 - acc: 0.9694 - val_loss: 3.7229 - val_acc: 0.4866\n",
      "Epoch 91/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1127 - acc: 0.9666 - val_loss: 3.6706 - val_acc: 0.4855\n",
      "Epoch 92/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0993 - acc: 0.9694 - val_loss: 3.6673 - val_acc: 0.4941\n",
      "Epoch 93/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1001 - acc: 0.9678 - val_loss: 3.7259 - val_acc: 0.4726\n",
      "Epoch 94/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0922 - acc: 0.9731 - val_loss: 3.6871 - val_acc: 0.4748\n",
      "Epoch 95/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0786 - acc: 0.9761 - val_loss: 3.7414 - val_acc: 0.4651\n",
      "Epoch 96/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1023 - acc: 0.9682 - val_loss: 3.7787 - val_acc: 0.4844\n",
      "Epoch 97/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0895 - acc: 0.9747 - val_loss: 3.7143 - val_acc: 0.4876\n",
      "Epoch 98/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.1098 - acc: 0.9685 - val_loss: 3.6360 - val_acc: 0.4791\n",
      "Epoch 99/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0858 - acc: 0.9731 - val_loss: 3.7660 - val_acc: 0.4844\n",
      "Epoch 100/100\n",
      "4346/4346 [==============================] - 38s - loss: 0.0875 - acc: 0.9733 - val_loss: 3.6681 - val_acc: 0.4855\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=100,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's plot the loss function the loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 50 epochs, we've got a final validation accuracy of around 50%. We've held out a test set for final evaluation which we do in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 3.7721598874857496)\n",
      "('Test accuracy:', 0.49463519313304721)\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we see that we have achieved a (top-1) accuracy of around 50%. That's not too bad for 6000 images, considering that if we were to use a naive strategy of taking random guesses, we would have only gotten around 1% accuracy. \n",
    "\n",
    "Now we can move on to the main strategy for training an image classifier on our small dataset: by starting with a larger and already trained network.\n",
    "\n",
    "To start, we will load the VGG16 from keras, which was trained on ImageNet and the weights saved online. If this is your first time loading VGG16, you'll need to wait a bit for the weights to download from the web. Once the network is loaded, we can inspect the layers with the `summary()` method again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544.0\n",
      "Trainable params: 138,357,544.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice that VGG16 is much bigger than the network we constructed. It contains 13 convolutional layers and two fully connected layers at the end, and has over 138 million parameters, around 100 times more parameters than the network we made above. Like our first network, a large proportion of the weights are stored in the connections leading into the first fully-connected layer.\n",
    "\n",
    "VGG16 was made to solve ImageNet, and achieves a [8.8% top-5 error rate](https://github.com/jcjohnson/cnn-benchmarks), which means that 91.2% of test samples were classified correctly within the top 5 predictions for each image. It's top-1 accuracy--equivalent to the accuracy metric we've been using (that the top prediction is correct)--is 73%. This is especially impressive since there are not just 97, but 1000 classes, meaning that random guesses would get us only 0.1% accuracy.\n",
    "\n",
    "In order to use this network for our task, we remove the final classification layer, the 1000-neuron softmax layer at the end, which corresponds to ImageNet, and instead replace it with a new softmax layer for our dataset, which contains 97 neurons in the case of the 101_ObjectCategories dataset. \n",
    "\n",
    "In terms of implementation, it's easier to simply create a copy of VGG from its input layer until the second to last layer, and then work with that, rather than modifying the VGG object directly. So technically we never remove anything, we just circumvent/ignore it. This can be done in the following way, by using the keras `Model` class to initialize a new model whose input layer is the same as VGG but whose output layer is our new softmax layer, called `new_classification_layer`. Note: although it appears we are duplicating this large network, internally Keras is actually just copying all the layers by reference, and thus we don't need to worry about overloading the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a reference to VGG's input layer\n",
    "inp = vgg.input\n",
    "\n",
    "# make a new softmax layer with num_classes neurons\n",
    "new_classification_layer = Dense(num_classes, activation='softmax')\n",
    "\n",
    "# connect our new layer to the second to last layer in VGG, and make a reference to it\n",
    "out = new_classification_layer(vgg.layers[-2].output)\n",
    "\n",
    "# create a new network between inp and out\n",
    "model_new = Model(inp, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to retrain this network on the new classifications. But first, we need to freeze the weights and biases in all the layers in the network, except our new one at the end. The point is that the features that were learned in VGG should still be fairly relevant to the new image classification task. Not perfectly optimal, but most likely better than what we can find in our limited dataset. By setting the `trainable` flag in each layer false (except our new classification layer), we ensure all the weights and biases in those layers remain fixed, and we simply \"fine-tune\" the parameters in the one layer at the end. \n",
    "\n",
    "Note that sometimes you don't have to freeze all the pre-classification layers. If you have enough data, it may be desirable to retrain more than just the one layer at the end. In our case, we don't have enough samples for this to work very well, so we simply go ahead with the plan.\n",
    "\n",
    "After freezing the other layers, we compile the model with exactly the same optimizer and loss function as in our first network, for the sake of a fair comparison. We then run `summary` again to look at the network's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 97)                397409    \n",
      "=================================================================\n",
      "Total params: 134,657,953.0\n",
      "Trainable params: 397,409.0\n",
      "Non-trainable params: 134,260,544.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# make\n",
    "for l, layer in enumerate(model_new.layers[:-1]):\n",
    "    layer.trainable = False\n",
    "\n",
    "for l, layer in enumerate(model_new.layers[-1:]):\n",
    "    layer.trainable = True\n",
    "    \n",
    "model_new.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_new.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the summary, we see the network is identical to the vgg model we instantiated earlier, except the last layer, formerly a 1000-neuron softmax, has been replaced by a new 97-neuron softmax. Additionally, we still have roughly 134 million weights, but now the vast majority of them are \"non-trainable params\" because we froze the layers they are contained in. We now only have 397,000 trainable parameters, which is actually only a fourth of the number of parameters needed to train the first model.\n",
    "\n",
    "As before, we go ahead and train the new model, using the same hyperparametrs (batch size and number of epochs) as before, along with the same optimization algorithm. We also keep track of its history as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4346 samples, validate on 931 samples\n",
      "Epoch 1/100\n",
      "4346/4346 [==============================] - 36s - loss: 4.2942 - acc: 0.0900 - val_loss: 3.7752 - val_acc: 0.1472\n",
      "Epoch 2/100\n",
      "4346/4346 [==============================] - 36s - loss: 3.4561 - acc: 0.2584 - val_loss: 3.2105 - val_acc: 0.3212\n",
      "Epoch 3/100\n",
      "4346/4346 [==============================] - 36s - loss: 2.9204 - acc: 0.3684 - val_loss: 2.7843 - val_acc: 0.3910\n",
      "Epoch 4/100\n",
      "4346/4346 [==============================] - 36s - loss: 2.5652 - acc: 0.4473 - val_loss: 2.5515 - val_acc: 0.4823\n",
      "Epoch 5/100\n",
      "4346/4346 [==============================] - 36s - loss: 2.2863 - acc: 0.5166 - val_loss: 2.2879 - val_acc: 0.4791\n",
      "Epoch 6/100\n",
      "4346/4346 [==============================] - 36s - loss: 2.0762 - acc: 0.5511 - val_loss: 2.1597 - val_acc: 0.5188\n",
      "Epoch 7/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.9124 - acc: 0.5874 - val_loss: 1.9776 - val_acc: 0.5585\n",
      "Epoch 8/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.7626 - acc: 0.6197 - val_loss: 1.9062 - val_acc: 0.5671\n",
      "Epoch 9/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.6470 - acc: 0.6523 - val_loss: 1.7965 - val_acc: 0.5994\n",
      "Epoch 10/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.5568 - acc: 0.6707 - val_loss: 1.6949 - val_acc: 0.6079\n",
      "Epoch 11/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.4616 - acc: 0.6901 - val_loss: 1.6447 - val_acc: 0.6047\n",
      "Epoch 12/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.3878 - acc: 0.7103 - val_loss: 1.5615 - val_acc: 0.6337\n",
      "Epoch 13/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.3259 - acc: 0.7112 - val_loss: 1.5190 - val_acc: 0.6488\n",
      "Epoch 14/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.2700 - acc: 0.7333 - val_loss: 1.4809 - val_acc: 0.6574\n",
      "Epoch 15/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.2156 - acc: 0.7430 - val_loss: 1.4060 - val_acc: 0.6874\n",
      "Epoch 16/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.1614 - acc: 0.7545 - val_loss: 1.3809 - val_acc: 0.6702\n",
      "Epoch 17/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.1213 - acc: 0.7549 - val_loss: 1.3757 - val_acc: 0.6735\n",
      "Epoch 18/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.0823 - acc: 0.7623 - val_loss: 1.3053 - val_acc: 0.6992\n",
      "Epoch 19/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.0498 - acc: 0.7743 - val_loss: 1.2646 - val_acc: 0.6917\n",
      "Epoch 20/100\n",
      "4346/4346 [==============================] - 36s - loss: 1.0119 - acc: 0.7780 - val_loss: 1.2462 - val_acc: 0.6982\n",
      "Epoch 21/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.9782 - acc: 0.7902 - val_loss: 1.2202 - val_acc: 0.7014\n",
      "Epoch 22/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.9491 - acc: 0.7936 - val_loss: 1.2190 - val_acc: 0.7025\n",
      "Epoch 23/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.9309 - acc: 0.7927 - val_loss: 1.2055 - val_acc: 0.7068\n",
      "Epoch 24/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.8900 - acc: 0.8125 - val_loss: 1.1590 - val_acc: 0.7186\n",
      "Epoch 25/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.8782 - acc: 0.8127 - val_loss: 1.1377 - val_acc: 0.7272\n",
      "Epoch 26/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.8557 - acc: 0.8097 - val_loss: 1.1375 - val_acc: 0.7057\n",
      "Epoch 27/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.8281 - acc: 0.8180 - val_loss: 1.1416 - val_acc: 0.7111\n",
      "Epoch 28/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.8066 - acc: 0.8233 - val_loss: 1.1032 - val_acc: 0.7218\n",
      "Epoch 29/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.7975 - acc: 0.8208 - val_loss: 1.0881 - val_acc: 0.7272\n",
      "Epoch 30/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.7724 - acc: 0.8302 - val_loss: 1.0782 - val_acc: 0.7304\n",
      "Epoch 31/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.7553 - acc: 0.8329 - val_loss: 1.0862 - val_acc: 0.7175\n",
      "Epoch 32/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.7379 - acc: 0.8382 - val_loss: 1.0506 - val_acc: 0.7390\n",
      "Epoch 33/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.7256 - acc: 0.8376 - val_loss: 1.0220 - val_acc: 0.7551\n",
      "Epoch 34/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.7063 - acc: 0.8433 - val_loss: 1.0208 - val_acc: 0.7379\n",
      "Epoch 35/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.6978 - acc: 0.8442 - val_loss: 0.9990 - val_acc: 0.7540\n",
      "Epoch 36/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.6751 - acc: 0.8530 - val_loss: 1.0387 - val_acc: 0.7272\n",
      "Epoch 37/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.6700 - acc: 0.8442 - val_loss: 0.9966 - val_acc: 0.7476\n",
      "Epoch 38/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.6557 - acc: 0.8573 - val_loss: 0.9849 - val_acc: 0.7594\n",
      "Epoch 39/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.6431 - acc: 0.8585 - val_loss: 0.9924 - val_acc: 0.7465\n",
      "Epoch 40/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.6315 - acc: 0.8679 - val_loss: 0.9706 - val_acc: 0.7487\n",
      "Epoch 41/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.6202 - acc: 0.8603 - val_loss: 0.9716 - val_acc: 0.7530\n",
      "Epoch 42/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.6090 - acc: 0.8677 - val_loss: 0.9680 - val_acc: 0.7583\n",
      "Epoch 43/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.5978 - acc: 0.8677 - val_loss: 0.9738 - val_acc: 0.7530\n",
      "Epoch 44/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5870 - acc: 0.8744 - val_loss: 0.9347 - val_acc: 0.7766\n",
      "Epoch 45/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.5753 - acc: 0.8771 - val_loss: 0.9095 - val_acc: 0.7701\n",
      "Epoch 46/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5675 - acc: 0.8792 - val_loss: 0.9525 - val_acc: 0.7573\n",
      "Epoch 47/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5587 - acc: 0.8753 - val_loss: 0.9459 - val_acc: 0.7476\n",
      "Epoch 48/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5555 - acc: 0.8794 - val_loss: 0.9261 - val_acc: 0.7530\n",
      "Epoch 49/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5383 - acc: 0.8836 - val_loss: 0.9454 - val_acc: 0.7454\n",
      "Epoch 50/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5342 - acc: 0.8840 - val_loss: 0.9138 - val_acc: 0.7615\n",
      "Epoch 51/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5291 - acc: 0.8870 - val_loss: 0.9070 - val_acc: 0.7573\n",
      "Epoch 52/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5148 - acc: 0.8861 - val_loss: 0.9018 - val_acc: 0.7680\n",
      "Epoch 53/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5096 - acc: 0.8886 - val_loss: 0.9226 - val_acc: 0.7530\n",
      "Epoch 54/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.5027 - acc: 0.8939 - val_loss: 0.8943 - val_acc: 0.7744\n",
      "Epoch 55/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4936 - acc: 0.8960 - val_loss: 0.9074 - val_acc: 0.7691\n",
      "Epoch 56/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4879 - acc: 0.8953 - val_loss: 0.9124 - val_acc: 0.7540\n",
      "Epoch 57/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4792 - acc: 0.8965 - val_loss: 0.8896 - val_acc: 0.7744\n",
      "Epoch 58/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4755 - acc: 0.8960 - val_loss: 0.8891 - val_acc: 0.7658\n",
      "Epoch 59/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4682 - acc: 0.9008 - val_loss: 0.8810 - val_acc: 0.7701\n",
      "Epoch 60/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4641 - acc: 0.8985 - val_loss: 0.8869 - val_acc: 0.7820\n",
      "Epoch 61/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4495 - acc: 0.9036 - val_loss: 0.8652 - val_acc: 0.7744\n",
      "Epoch 62/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.4485 - acc: 0.9040 - val_loss: 0.8858 - val_acc: 0.7680\n",
      "Epoch 63/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.4396 - acc: 0.9103 - val_loss: 0.8642 - val_acc: 0.7755\n",
      "Epoch 64/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.4323 - acc: 0.9116 - val_loss: 0.8702 - val_acc: 0.7798\n",
      "Epoch 65/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4302 - acc: 0.9059 - val_loss: 0.8904 - val_acc: 0.7594\n",
      "Epoch 66/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.4272 - acc: 0.9110 - val_loss: 0.8638 - val_acc: 0.7744\n",
      "Epoch 67/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4167 - acc: 0.9146 - val_loss: 0.8752 - val_acc: 0.7723\n",
      "Epoch 68/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.4100 - acc: 0.9183 - val_loss: 0.8653 - val_acc: 0.7787\n",
      "Epoch 69/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.4076 - acc: 0.9144 - val_loss: 0.8573 - val_acc: 0.7658\n",
      "Epoch 70/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.4026 - acc: 0.9162 - val_loss: 0.8291 - val_acc: 0.7798\n",
      "Epoch 71/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3964 - acc: 0.9185 - val_loss: 0.8721 - val_acc: 0.7701\n",
      "Epoch 72/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3944 - acc: 0.9156 - val_loss: 0.8509 - val_acc: 0.7787\n",
      "Epoch 73/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3897 - acc: 0.9197 - val_loss: 0.8458 - val_acc: 0.7744\n",
      "Epoch 74/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3819 - acc: 0.9206 - val_loss: 0.8388 - val_acc: 0.7852\n",
      "Epoch 75/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3787 - acc: 0.9215 - val_loss: 0.8281 - val_acc: 0.7691\n",
      "Epoch 76/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3757 - acc: 0.9213 - val_loss: 0.8352 - val_acc: 0.7701\n",
      "Epoch 77/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3713 - acc: 0.9287 - val_loss: 0.8344 - val_acc: 0.7766\n",
      "Epoch 78/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3664 - acc: 0.9243 - val_loss: 0.8259 - val_acc: 0.7830\n",
      "Epoch 79/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3614 - acc: 0.9273 - val_loss: 0.8162 - val_acc: 0.7830\n",
      "Epoch 80/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3563 - acc: 0.9271 - val_loss: 0.8301 - val_acc: 0.7734\n",
      "Epoch 81/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3527 - acc: 0.9261 - val_loss: 0.8223 - val_acc: 0.7863\n",
      "Epoch 82/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3499 - acc: 0.9294 - val_loss: 0.7862 - val_acc: 0.7927\n",
      "Epoch 83/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3399 - acc: 0.9342 - val_loss: 0.8135 - val_acc: 0.7766\n",
      "Epoch 84/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3410 - acc: 0.9337 - val_loss: 0.8146 - val_acc: 0.7830\n",
      "Epoch 85/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3354 - acc: 0.9335 - val_loss: 0.7957 - val_acc: 0.7905\n",
      "Epoch 86/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3355 - acc: 0.9314 - val_loss: 0.8126 - val_acc: 0.7820\n",
      "Epoch 87/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3307 - acc: 0.9344 - val_loss: 0.8042 - val_acc: 0.7820\n",
      "Epoch 88/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3240 - acc: 0.9386 - val_loss: 0.7895 - val_acc: 0.8002\n",
      "Epoch 89/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3210 - acc: 0.9388 - val_loss: 0.8042 - val_acc: 0.7927\n",
      "Epoch 90/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3167 - acc: 0.9365 - val_loss: 0.8036 - val_acc: 0.7809\n",
      "Epoch 91/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3138 - acc: 0.9416 - val_loss: 0.7923 - val_acc: 0.7863\n",
      "Epoch 92/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3126 - acc: 0.9390 - val_loss: 0.7948 - val_acc: 0.7916\n",
      "Epoch 93/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3083 - acc: 0.9422 - val_loss: 0.7973 - val_acc: 0.7895\n",
      "Epoch 94/100\n",
      "4346/4346 [==============================] - 37s - loss: 0.3057 - acc: 0.9422 - val_loss: 0.7880 - val_acc: 0.7916\n",
      "Epoch 95/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.3004 - acc: 0.9448 - val_loss: 0.8244 - val_acc: 0.7755\n",
      "Epoch 96/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.2986 - acc: 0.9439 - val_loss: 0.7961 - val_acc: 0.7884\n",
      "Epoch 97/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.2966 - acc: 0.9459 - val_loss: 0.7892 - val_acc: 0.7927\n",
      "Epoch 98/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.2932 - acc: 0.9439 - val_loss: 0.7866 - val_acc: 0.8002\n",
      "Epoch 99/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.2887 - acc: 0.9473 - val_loss: 0.7858 - val_acc: 0.7948\n",
      "Epoch 100/100\n",
      "4346/4346 [==============================] - 36s - loss: 0.2862 - acc: 0.9471 - val_loss: 0.7880 - val_acc: 0.7841\n"
     ]
    }
   ],
   "source": [
    "history = model_new.fit(x_train, y_train, \n",
    "                        batch_size=128, \n",
    "                        epochs=100, \n",
    "                        validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 0.80789021463353239)\n",
      "('Test accuracy:', 0.78218884120171672)\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.2941599179674723, 3.4560996727958782, 2.9204496808497522, 2.5652155076310867, 2.2863048170768221, 2.0761643421578615, 1.9123944168643803, 1.7626441612915131, 1.6470325468215206, 1.5567548332596177, 1.461559222142816, 1.3878308535719379, 1.3259043960158747, 1.269991418978502, 1.2155848767863844, 1.1613779493152849, 1.1213186751627671, 1.0822984447031596, 1.0497851623843686, 1.0119208326495521, 0.97815125434562133, 0.94910008806925572, 0.93093975625496772, 0.89004653396005184, 0.87818294110739226, 0.85566686563540095, 0.82809179634527841, 0.80655441910124459, 0.79747256020823765, 0.77239716209358078, 0.75532895721601445, 0.73794520611703751, 0.72564979678631047, 0.70633917750710995, 0.69781448009427771, 0.67514473449454238, 0.66999329754793857, 0.65574898209047383, 0.64311635812416201, 0.63145963428649166, 0.62019149704677301, 0.6089866509428784, 0.59779670067882407, 0.58700551171484927, 0.57532888925190739, 0.56747167057229586, 0.55867116395306926, 0.55548610612647187, 0.53832311963245061, 0.53415971806506879, 0.52911136408747472, 0.51479554510972381, 0.50960640497488519, 0.50272838259094388, 0.49363362605375349, 0.4879028945269806, 0.47918731333525894, 0.47546959636510927, 0.46822768260518693, 0.46407099107252087, 0.44949488818398609, 0.44852021077345222, 0.43956984633736712, 0.43229719355969837, 0.43018495969326881, 0.42721930486345094, 0.4166547201138403, 0.40995034265507219, 0.40764864442593152, 0.40263706517011078, 0.39639394075103579, 0.39443316364474851, 0.38966812061045614, 0.38191798211405809, 0.37866501816669695, 0.37565754542578983, 0.37125564632303859, 0.36639254307395785, 0.36142636032571895, 0.35632665824955967, 0.35271167382083618, 0.34994054759530718, 0.33986765100996558, 0.34101917780164304, 0.33540370295083966, 0.33553950009234096, 0.33068207412395839, 0.32403070435401105, 0.32097073563825024, 0.31673254316104377, 0.31378405810335075, 0.31259317406025888, 0.30832410355180406, 0.30572872548897695, 0.30036015229130802, 0.29856314787489446, 0.29661729502557227, 0.29319842997724099, 0.28865997729847853, 0.28616761745695579]\n",
      "[0.089967786422315635, 0.25839852729921126, 0.36838472151449075, 0.44730786898966707, 0.51656695872586389, 0.55108145423819821, 0.58743672293010418, 0.61965025269485974, 0.65232397648139429, 0.67073170772851798, 0.69005982468767868, 0.71030832908694452, 0.71122871614303451, 0.7333179931184195, 0.74298205290090857, 0.75448688462863467, 0.75494707766294589, 0.76231017098468512, 0.77427519574672243, 0.77795674172185059, 0.79015186424909289, 0.79360331328190581, 0.79268292614352687, 0.81247123756334083, 0.81270133475252304, 0.8097100783974357, 0.81799355660832207, 0.82328578021961918, 0.82075471629539065, 0.83018867886126779, 0.83294983970038194, 0.8382420615836107, 0.83755177111325041, 0.84330418849945943, 0.8442245750618157, 0.85296824712990293, 0.84422457478751911, 0.85734008217647883, 0.85849056625717313, 0.86792452800016051, 0.86033133850413646, 0.86769443215503161, 0.86769443210017227, 0.87436723443038777, 0.87712839469347914, 0.87919926305986795, 0.87528762126704052, 0.8794293597004571, 0.88357109923105992, 0.8840312928139642, 0.88702254938848879, 0.88610216310042911, 0.88863322647606457, 0.89392544835929322, 0.89599631839889127, 0.89530602932744352, 0.89645651165263973, 0.89599631897491405, 0.90082834867415096, 0.89852738229569018, 0.90358950726403331, 0.90404970139553076, 0.91026231066400531, 0.9116428896846499, 0.90589047476711004, 0.91095260061320216, 0.91463414601230753, 0.91831569226173226, 0.91440405022203786, 0.91624482334675028, 0.91854578862802472, 0.91555453369927964, 0.91969627265385967, 0.92061665924364555, 0.92153704605286868, 0.92130694858938988, 0.92867004111566909, 0.92429820464275092, 0.92728946097040854, 0.92705936518013887, 0.9261389788920793, 0.92936033186032596, 0.93419236161442221, 0.93373216805894754, 0.93350207084233561, 0.93143120162562731, 0.93442245740469188, 0.93856419635927191, 0.93879429302729056, 0.93649332716999323, 0.94155545298865573, 0.93902438994217619, 0.94224574318471943, 0.94224574291042285, 0.94477680650549556, 0.94385641909282003, 0.94592729028446354, 0.94385642051916219, 0.94730787010056816, 0.94707777260965975]\n",
      "[3.7752230910046145, 3.2105069836535591, 2.7842566833844375, 2.5514855482140364, 2.2879259089522153, 2.1596893127187364, 1.9776205022916373, 1.9062158139512566, 1.7964960054987611, 1.6949020045400307, 1.6446723815065705, 1.5614853980845975, 1.518971624999246, 1.4809107243950719, 1.4060098561513308, 1.3809291330495275, 1.3757332325237779, 1.3053016831616198, 1.2645573536640335, 1.2462445576900314, 1.2202056006125297, 1.2190298890708982, 1.2054502209838556, 1.1590063195479543, 1.1377127721153448, 1.1375446812550825, 1.141556605104473, 1.1031993901563126, 1.088105549105512, 1.0781761654977768, 1.0862198627596895, 1.0506353456402953, 1.0220059489333155, 1.0207915682541697, 0.99898812530120129, 1.0386640318738403, 0.99656319848704922, 0.98491029426951671, 0.99240134033813643, 0.97063735258694495, 0.97157066964437322, 0.96804863835507893, 0.97381840190108937, 0.93472117140777133, 0.90945478963288529, 0.95254614030508167, 0.94591867949345443, 0.92610950154981608, 0.94543943817454168, 0.91381687393249933, 0.90699770755337594, 0.90180374357037074, 0.92263844087479829, 0.89433776231124495, 0.90738211372100963, 0.91243975528712939, 0.88959526016940105, 0.88905463733427248, 0.88095701534689175, 0.88693857244210905, 0.86523967706043148, 0.88575348626146, 0.86421727263453696, 0.87024306943670127, 0.89037904280981106, 0.86377923188993166, 0.87523805903056762, 0.86527883238234149, 0.85728394639479233, 0.82905098306121172, 0.87207374050332964, 0.85085915968574333, 0.84577870548219614, 0.83883259811155519, 0.82812836487746522, 0.83515871979624323, 0.83441944844484583, 0.82590651678603655, 0.8161724652178689, 0.83006890708726666, 0.822252866276865, 0.78618385776413247, 0.81346622855271489, 0.81456110492812828, 0.79571337525749819, 0.81255154578949529, 0.80422385281830167, 0.78949176381661224, 0.80422823680074595, 0.80358572062565103, 0.79234844324540121, 0.79478536166898928, 0.79730283279296021, 0.7879607266437354, 0.82437494464386674, 0.79614854627213849, 0.78923207515036387, 0.78655320335535694, 0.78576276471356188, 0.78802258179600082]\n",
      "[0.14715359830542615, 0.32116004318863184, 0.39097744402516671, 0.48227712159894337, 0.4790547808950365, 0.51879699356957998, 0.55853920598803475, 0.56713211709267342, 0.59935553258266916, 0.607948443367197, 0.60472610199105725, 0.63372717610491336, 0.64876476989780918, 0.65735768068233702, 0.68743286865226183, 0.67024704695516191, 0.67346938845934601, 0.69924812100499578, 0.69172932407653676, 0.69817400727697143, 0.7013963487171333, 0.70247046250917988, 0.70676691799747704, 0.71858217041423322, 0.72717508119876095, 0.70569280414140823, 0.71106337335772984, 0.72180451191841721, 0.72717508119876095, 0.73039742276696717, 0.71750805636609793, 0.73899033361551714, 0.75510204139252612, 0.73791621975944843, 0.75402792766450166, 0.72717508126278307, 0.74758324459211145, 0.7593984969448454, 0.74650913067202052, 0.74865735838415803, 0.75295381387245519, 0.75832438302475447, 0.75295381374441084, 0.77658431857792309, 0.77013963544151065, 0.75725026916868576, 0.74758324433602275, 0.75295381374441084, 0.74543501687997393, 0.76154672446491634, 0.75725026910466364, 0.76799140779339536, 0.75295381374441084, 0.77443609092980781, 0.76906552164946407, 0.75402792760047954, 0.77443609092980781, 0.76584318008125785, 0.77013963550553288, 0.78195488785826683, 0.77443609086578569, 0.76799140766535101, 0.77551020478587662, 0.77980666014612943, 0.75939849688082328, 0.77443609099383004, 0.7722878632176704, 0.77873254629006061, 0.76584317995321349, 0.77980666014612943, 0.77013963544151065, 0.77873254629006061, 0.77443609086578569, 0.78517722949049529, 0.76906552164946407, 0.77013963550553288, 0.77658431864194533, 0.78302900165031342, 0.78302900171433565, 0.77336197700971687, 0.78625134321851964, 0.79269602635493208, 0.77658431851390097, 0.78302900165031342, 0.79054779877083903, 0.78195488805033342, 0.78195488792228907, 0.80021482334741334, 0.79269602641895431, 0.78088077400219813, 0.78625134334656399, 0.7916219125628855, 0.78947368472270374, 0.7916219125628855, 0.77551020478587662, 0.78839957099467928, 0.79269602641895431, 0.80021482334741334, 0.7948442540670696, 0.7841031156984487]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['loss'])\n",
    "print(history.history['acc'])\n",
    "\n",
    "print(history.history['val_loss'])\n",
    "print(history.history['val_acc'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving results\n",
    "\n",
    "Can improve by doing augmentation on data\n",
    "running longer, trying different optimizers and hyperparams (keep val set)\n",
    "\n",
    "compare to imagenet results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "matplotlib.pyplot.switch_backend('agg')\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(16,4))\n",
    "matplotlib.pyplot.plot(np.array([1,2,3,4,5]))\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "history.history['val_acc']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
