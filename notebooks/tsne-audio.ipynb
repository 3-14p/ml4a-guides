{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "\n",
    "def get_audio_files(path, extension):\n",
    "\tfiles = []\n",
    "\tfor root, dirnames, filenames in os.walk(path):\n",
    "\t    for filename in fnmatch.filter(filenames, '*.'+extension):\n",
    "\t        files.append(os.path.join(root, filename))\n",
    "\treturn files\n",
    "\n",
    "def get_features(y, sr):\n",
    "\ty = y[0:sr] \t# analyze just first second\n",
    "\t#S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "\t#S = librosa.feature.mfcc(y, sr=sr)\n",
    "\t#log_S = librosa.logamplitude(S, ref_power=np.max)\n",
    "\tS = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "\tlog_S = librosa.logamplitude(S, ref_power=np.max)\n",
    "\tmfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
    "\tdelta_mfcc = librosa.feature.delta(mfcc)\n",
    "\tdelta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "\t#mean_mfcc = np.mean(S, 1)\n",
    "\t#mean_mfcc = (mean_mfcc-np.mean(mean_mfcc))/np.std(mean_mfcc)\n",
    "\t#var_mfcc = np.var(S, 1)\n",
    "\t#var_mfcc = (var_mfcc-np.mean(var_mfcc))/np.std(var_mfcc)\n",
    "\t#feature_vector = np.concatenate((mean_mfcc, var_mfcc))\n",
    "\tfeature_vector = np.concatenate((np.mean(mfcc,1), np.mean(delta_mfcc,1), np.mean(delta2_mfcc,1)))\n",
    "\tfeature_vector = (feature_vector-np.mean(feature_vector))/np.std(feature_vector)\n",
    "\treturn feature_vector\n",
    "\n",
    "def segment_analyze_audio_file(source_audio, save_path_audio, hop_length_=512):\n",
    "\ty, sr = librosa.load(source_audio)\n",
    "\tonsets = librosa.onset.onset_detect(y=y, sr=sr, hop_length=hop_length_)\n",
    "\tfeature_vectors = []\n",
    "\tfor i in range(len(onsets)-1):\n",
    "\t\tidx_y1 = onsets[i] * hop_length\n",
    "\t\tidx_y2 = onsets[i+1] * hop_length\n",
    "\t\ty_ = y[idx_y1:idx_y2]\n",
    "\t\tfeat = get_features(y_, sr)\n",
    "\t\tfile_path = '%s/onset_%d.wav' % (save_path_audio, i)\n",
    "\t\tfeature_vectors.append({\"file\":file_path, \"features\":feat})\n",
    "\t\tlibrosa.output.write_wav(file_path, y_, sr)\n",
    "\t\tprint \"analyzed %d/%d = %s\"%(i, len(onsets)-1, file_path)\n",
    "\treturn feature_vectors\n",
    "\n",
    "def analyze_directory(source_audio):\t\n",
    "\tfiles = get_audio_files(source_audio, 'wav')\n",
    "\tfeature_vectors = []\n",
    "\tfor i,f in enumerate(files):\n",
    "\t\tprint \"get: %d/%d = %s\"%(i, len(files), f)\n",
    "\t\ty, sr = librosa.load(f)\n",
    "\t\tfeat = get_features(y, sr)\n",
    "\t\tfeature_vectors.append({\"file\":f, \"features\":feat})\n",
    "\treturn feature_vectors\n",
    "\n",
    "def run_tSNE(feature_vectors, save_path_points, perplexity_=30):\n",
    "\tmodel = TSNE(n_components=2, perplexity=perplexity_, verbose=2, angle=0.1).fit_transform([f[\"features\"] for f in feature_vectors])\n",
    "\tx_axis=model[:,0] # normalize t-SNE\n",
    "\ty_axis=model[:,1]\n",
    "\tx_norm = (x_axis-np.min(x_axis)) / (np.max(x_axis) - np.min(x_axis))\n",
    "\ty_norm = (y_axis-np.min(y_axis)) / (np.max(y_axis) - np.min(y_axis))\n",
    "\tdata = []\n",
    "\tfor i,f in enumerate(feature_vectors):\n",
    "\t\tdata.append({\"path\":f[\"file\"], \"x\":x_norm[i], \"y\":y_norm[i]})\n",
    "\twith open(save_path_points, 'w') as outfile:\n",
    "\t    json.dump(data, outfile)\n",
    "\tprint(\"finished saving %s\"%save_path_points)\n",
    "\n",
    "\n",
    "\n",
    "source_audio = '/Users/gene/Downloads/QUEEN+-+Bohemian+Rhapsody(music.naij.com).mp3'\n",
    "save_path_audio = '/Users/gene/Desktop/temp/'\n",
    "save_path_points = 'tsnetest.json'\n",
    "hop_length = 512\n",
    "\n",
    "\n",
    "feature_vectors = segment_analyze_audio_file(source_audio, save_path_audio, hop_length)\n",
    "run_tSNE(feature_vectors, save_path_points)\n",
    "\n",
    "\n",
    "\n",
    "source_audio = '/Users/gene/audio/Drum Samples'\n",
    "save_path_points = 'tsnetest.json'\n",
    "\n",
    "feature_vectors = analyze_directory(source_audio)\n",
    "run_tSNE(feature_vectors, save_path_points)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
