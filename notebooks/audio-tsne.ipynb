{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook will show you how to create a t-SNE plot of a group of audio clips. The code is below, but has not yet been annotated. Check back in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_audio_files(path, extension):\n",
    "    files = []\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in fnmatch.filter(filenames, '*.'+extension):\n",
    "            files.append(os.path.join(root, filename))\n",
    "    return files\n",
    "\n",
    "def get_features(y, sr):\n",
    "    y = y[0:sr] \t# analyze just first second\n",
    "    #S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "    #S = librosa.feature.mfcc(y, sr=sr)\n",
    "    #log_S = librosa.logamplitude(S, ref_power=np.max)\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "    log_S = librosa.logamplitude(S, ref_power=np.max)\n",
    "    mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
    "    delta_mfcc = librosa.feature.delta(mfcc)\n",
    "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "    #mean_mfcc = np.mean(S, 1)\n",
    "    #mean_mfcc = (mean_mfcc-np.mean(mean_mfcc))/np.std(mean_mfcc)\n",
    "    #var_mfcc = np.var(S, 1)\n",
    "    #var_mfcc = (var_mfcc-np.mean(var_mfcc))/np.std(var_mfcc)\n",
    "    #feature_vector = np.concatenate((mean_mfcc, var_mfcc))\n",
    "    feature_vector = np.concatenate((np.mean(mfcc,1), np.mean(delta_mfcc,1), np.mean(delta2_mfcc,1)))\n",
    "    feature_vector = (feature_vector-np.mean(feature_vector))/np.std(feature_vector)\n",
    "    return feature_vector\n",
    "\n",
    "def segment_analyze_audio_file(source_audio, save_path_audio, hop_length_=512):\n",
    "    y, sr = librosa.load(source_audio)\n",
    "    onsets = librosa.onset.onset_detect(y=y, sr=sr, hop_length=hop_length_)\n",
    "    feature_vectors = []\n",
    "    for i in range(len(onsets)-1):\n",
    "        idx_y1 = onsets[i] * hop_length\n",
    "        idx_y2 = onsets[i+1] * hop_length\n",
    "        y_ = y[idx_y1:idx_y2]\n",
    "        feat = get_features(y_, sr)\n",
    "        file_path = '%s/onset_%d.wav' % (save_path_audio, i)\n",
    "        feature_vectors.append({\"file\":file_path, \"features\":feat})\n",
    "        librosa.output.write_wav(file_path, y_, sr)\n",
    "        print \"analyzed %d/%d = %s\"%(i, len(onsets)-1, file_path)\n",
    "    return feature_vectors\n",
    "\n",
    "def analyze_directory(source_audio):\n",
    "    files = get_audio_files(source_audio, 'wav')\n",
    "    feature_vectors = []\n",
    "    for i,f in enumerate(files):\n",
    "        print \"get: %d/%d = %s\"%(i, len(files), f)\n",
    "        y, sr = librosa.load(f)\n",
    "        feat = get_features(y, sr)\n",
    "        feature_vectors.append({\"file\":f, \"features\":feat})\n",
    "    return feature_vectors\n",
    "\n",
    "def run_tSNE(feature_vectors, save_path_points, perplexity_=30):\n",
    "    model = TSNE(n_components=2, perplexity=perplexity_, verbose=2, angle=0.1).fit_transform([f[\"features\"] for f in feature_vectors])\n",
    "    x_axis=model[:,0] # normalize t-SNE\n",
    "    y_axis=model[:,1]\n",
    "    x_norm = (x_axis-np.min(x_axis)) / (np.max(x_axis) - np.min(x_axis))\n",
    "    y_norm = (y_axis-np.min(y_axis)) / (np.max(y_axis) - np.min(y_axis))\n",
    "    data = []\n",
    "    for i,f in enumerate(feature_vectors):\n",
    "        data.append({\"path\":f[\"file\"], \"x\":x_norm[i], \"y\":y_norm[i]})\n",
    "    with open(save_path_points, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    print(\"finished saving %s\"%save_path_points)\n",
    "\n",
    "\n",
    "\n",
    "source_audio = '/Users/gene/Downloads/QUEEN+-+Bohemian+Rhapsody(music.naij.com).mp3'\n",
    "save_path_audio = '/Users/gene/Desktop/temp/'\n",
    "save_path_points = 'tsnetest.json'\n",
    "hop_length = 512\n",
    "\n",
    "\n",
    "feature_vectors = segment_analyze_audio_file(source_audio, save_path_audio, hop_length)\n",
    "run_tSNE(feature_vectors, save_path_points)\n",
    "\n",
    "\n",
    "\n",
    "source_audio = '/Users/gene/audio/Drum Samples'\n",
    "save_path_points = 'tsnetest.json'\n",
    "\n",
    "feature_vectors = analyze_directory(source_audio)\n",
    "run_tSNE(feature_vectors, save_path_points)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
